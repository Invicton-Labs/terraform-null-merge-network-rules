locals {
  neg_inf     = -9e99
  pos_inf     = 9e99
  digit_count = 100
  // This is what we consider whole numbers for log2 calculations.
  // We use this value because Terraform returns 15 decimal places.
  log2_precision_allowance = 1e-14
  max_number_of_ranges = 100

  // STEPS:
  //  1. Sort ascending by "from" value
  //  2. For each rule, check if it's contiguous with the next one
  //  3. Then loop through and count how many rules forward it remains contiguous
  //  4. If it's a base2-aligned rule, do a pass to mark merges that would violate
  //     base2 alignment as non-contiguous.
  //  5. Then loop through and forward merge.

  // Add sort keys to each rule, which we use for sorting.
  range_0_with_sort_keys = {
    for group_key, group in local.reverse_pass_encapsulate :
    group_key => length(local.range_keys[group_key]) <= 0 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][0]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][0]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][0]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][0]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][0]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][0]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][0]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][0]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][0]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][0]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_0_sort_keys = {
    for group_key, group in local.range_0_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 0 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_0_sorted = {
    for group_key, group in local.range_0_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 0 ? null : merge(group, {
      rules = [
        for sort_key in local.range_0_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_0_next_contiguous = {
    for group_key, group in local.range_0_sorted :
    group_key => length(local.range_keys[group_key]) <= 0 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][0]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][0]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][0]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][0]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][0]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][0]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][0] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_0_contiguous_forward_count = {
    for group_key, group in local.range_0_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 0 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_0_contiguous_base2 = {
    for group_key, group in local.range_0_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 0 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][0]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][0]].to_inclusive - rule.ranges[local.range_keys[group_key][0]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][0]].to_inclusive - rule.ranges[local.range_keys[group_key][0]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][0]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][0]].to_inclusive - rule.ranges[local.range_keys[group_key][0]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_0_squashed = {
    for group_key, group in local.range_0_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 0 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][0] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_1_with_sort_keys = {
    for group_key, group in local.range_0_squashed :
    group_key => length(local.range_keys[group_key]) <= 1 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][1]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][1]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][1]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][1]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][1]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][1]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][1]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][1]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][1]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][1]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_1_sort_keys = {
    for group_key, group in local.range_1_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 1 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_1_sorted = {
    for group_key, group in local.range_1_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 1 ? null : merge(group, {
      rules = [
        for sort_key in local.range_1_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_1_next_contiguous = {
    for group_key, group in local.range_1_sorted :
    group_key => length(local.range_keys[group_key]) <= 1 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][1]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][1]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][1]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][1]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][1]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][1]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][1] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_1_contiguous_forward_count = {
    for group_key, group in local.range_1_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 1 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_1_contiguous_base2 = {
    for group_key, group in local.range_1_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 1 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][1]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][1]].to_inclusive - rule.ranges[local.range_keys[group_key][1]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][1]].to_inclusive - rule.ranges[local.range_keys[group_key][1]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][1]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][1]].to_inclusive - rule.ranges[local.range_keys[group_key][1]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_1_squashed = {
    for group_key, group in local.range_1_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 1 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][1] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_2_with_sort_keys = {
    for group_key, group in local.range_1_squashed :
    group_key => length(local.range_keys[group_key]) <= 2 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][2]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][2]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][2]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][2]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][2]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][2]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][2]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][2]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][2]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][2]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_2_sort_keys = {
    for group_key, group in local.range_2_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 2 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_2_sorted = {
    for group_key, group in local.range_2_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 2 ? null : merge(group, {
      rules = [
        for sort_key in local.range_2_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_2_next_contiguous = {
    for group_key, group in local.range_2_sorted :
    group_key => length(local.range_keys[group_key]) <= 2 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][2]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][2]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][2]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][2]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][2]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][2]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][2] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_2_contiguous_forward_count = {
    for group_key, group in local.range_2_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 2 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_2_contiguous_base2 = {
    for group_key, group in local.range_2_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 2 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][2]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][2]].to_inclusive - rule.ranges[local.range_keys[group_key][2]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][2]].to_inclusive - rule.ranges[local.range_keys[group_key][2]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][2]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][2]].to_inclusive - rule.ranges[local.range_keys[group_key][2]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_2_squashed = {
    for group_key, group in local.range_2_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 2 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][2] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_3_with_sort_keys = {
    for group_key, group in local.range_2_squashed :
    group_key => length(local.range_keys[group_key]) <= 3 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][3]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][3]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][3]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][3]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][3]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][3]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][3]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][3]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][3]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][3]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_3_sort_keys = {
    for group_key, group in local.range_3_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 3 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_3_sorted = {
    for group_key, group in local.range_3_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 3 ? null : merge(group, {
      rules = [
        for sort_key in local.range_3_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_3_next_contiguous = {
    for group_key, group in local.range_3_sorted :
    group_key => length(local.range_keys[group_key]) <= 3 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][3]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][3]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][3]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][3]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][3]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][3]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][3] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_3_contiguous_forward_count = {
    for group_key, group in local.range_3_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 3 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_3_contiguous_base2 = {
    for group_key, group in local.range_3_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 3 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][3]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][3]].to_inclusive - rule.ranges[local.range_keys[group_key][3]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][3]].to_inclusive - rule.ranges[local.range_keys[group_key][3]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][3]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][3]].to_inclusive - rule.ranges[local.range_keys[group_key][3]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_3_squashed = {
    for group_key, group in local.range_3_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 3 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][3] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_4_with_sort_keys = {
    for group_key, group in local.range_3_squashed :
    group_key => length(local.range_keys[group_key]) <= 4 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][4]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][4]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][4]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][4]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][4]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][4]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][4]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][4]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][4]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][4]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_4_sort_keys = {
    for group_key, group in local.range_4_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 4 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_4_sorted = {
    for group_key, group in local.range_4_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 4 ? null : merge(group, {
      rules = [
        for sort_key in local.range_4_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_4_next_contiguous = {
    for group_key, group in local.range_4_sorted :
    group_key => length(local.range_keys[group_key]) <= 4 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][4]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][4]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][4]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][4]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][4]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][4]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][4] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_4_contiguous_forward_count = {
    for group_key, group in local.range_4_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 4 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_4_contiguous_base2 = {
    for group_key, group in local.range_4_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 4 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][4]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][4]].to_inclusive - rule.ranges[local.range_keys[group_key][4]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][4]].to_inclusive - rule.ranges[local.range_keys[group_key][4]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][4]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][4]].to_inclusive - rule.ranges[local.range_keys[group_key][4]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_4_squashed = {
    for group_key, group in local.range_4_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 4 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][4] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_5_with_sort_keys = {
    for group_key, group in local.range_4_squashed :
    group_key => length(local.range_keys[group_key]) <= 5 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][5]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][5]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][5]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][5]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][5]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][5]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][5]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][5]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][5]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][5]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_5_sort_keys = {
    for group_key, group in local.range_5_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 5 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_5_sorted = {
    for group_key, group in local.range_5_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 5 ? null : merge(group, {
      rules = [
        for sort_key in local.range_5_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_5_next_contiguous = {
    for group_key, group in local.range_5_sorted :
    group_key => length(local.range_keys[group_key]) <= 5 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][5]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][5]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][5]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][5]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][5]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][5]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][5] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_5_contiguous_forward_count = {
    for group_key, group in local.range_5_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 5 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_5_contiguous_base2 = {
    for group_key, group in local.range_5_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 5 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][5]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][5]].to_inclusive - rule.ranges[local.range_keys[group_key][5]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][5]].to_inclusive - rule.ranges[local.range_keys[group_key][5]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][5]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][5]].to_inclusive - rule.ranges[local.range_keys[group_key][5]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_5_squashed = {
    for group_key, group in local.range_5_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 5 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][5] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_6_with_sort_keys = {
    for group_key, group in local.range_5_squashed :
    group_key => length(local.range_keys[group_key]) <= 6 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][6]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][6]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][6]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][6]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][6]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][6]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][6]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][6]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][6]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][6]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_6_sort_keys = {
    for group_key, group in local.range_6_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 6 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_6_sorted = {
    for group_key, group in local.range_6_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 6 ? null : merge(group, {
      rules = [
        for sort_key in local.range_6_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_6_next_contiguous = {
    for group_key, group in local.range_6_sorted :
    group_key => length(local.range_keys[group_key]) <= 6 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][6]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][6]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][6]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][6]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][6]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][6]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][6] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_6_contiguous_forward_count = {
    for group_key, group in local.range_6_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 6 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_6_contiguous_base2 = {
    for group_key, group in local.range_6_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 6 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][6]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][6]].to_inclusive - rule.ranges[local.range_keys[group_key][6]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][6]].to_inclusive - rule.ranges[local.range_keys[group_key][6]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][6]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][6]].to_inclusive - rule.ranges[local.range_keys[group_key][6]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_6_squashed = {
    for group_key, group in local.range_6_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 6 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][6] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_7_with_sort_keys = {
    for group_key, group in local.range_6_squashed :
    group_key => length(local.range_keys[group_key]) <= 7 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][7]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][7]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][7]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][7]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][7]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][7]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][7]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][7]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][7]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][7]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_7_sort_keys = {
    for group_key, group in local.range_7_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 7 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_7_sorted = {
    for group_key, group in local.range_7_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 7 ? null : merge(group, {
      rules = [
        for sort_key in local.range_7_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_7_next_contiguous = {
    for group_key, group in local.range_7_sorted :
    group_key => length(local.range_keys[group_key]) <= 7 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][7]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][7]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][7]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][7]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][7]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][7]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][7] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_7_contiguous_forward_count = {
    for group_key, group in local.range_7_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 7 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_7_contiguous_base2 = {
    for group_key, group in local.range_7_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 7 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][7]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][7]].to_inclusive - rule.ranges[local.range_keys[group_key][7]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][7]].to_inclusive - rule.ranges[local.range_keys[group_key][7]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][7]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][7]].to_inclusive - rule.ranges[local.range_keys[group_key][7]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_7_squashed = {
    for group_key, group in local.range_7_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 7 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][7] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_8_with_sort_keys = {
    for group_key, group in local.range_7_squashed :
    group_key => length(local.range_keys[group_key]) <= 8 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][8]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][8]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][8]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][8]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][8]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][8]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][8]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][8]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][8]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][8]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_8_sort_keys = {
    for group_key, group in local.range_8_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 8 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_8_sorted = {
    for group_key, group in local.range_8_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 8 ? null : merge(group, {
      rules = [
        for sort_key in local.range_8_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_8_next_contiguous = {
    for group_key, group in local.range_8_sorted :
    group_key => length(local.range_keys[group_key]) <= 8 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][8]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][8]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][8]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][8]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][8]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][8]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][8] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_8_contiguous_forward_count = {
    for group_key, group in local.range_8_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 8 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_8_contiguous_base2 = {
    for group_key, group in local.range_8_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 8 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][8]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][8]].to_inclusive - rule.ranges[local.range_keys[group_key][8]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][8]].to_inclusive - rule.ranges[local.range_keys[group_key][8]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][8]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][8]].to_inclusive - rule.ranges[local.range_keys[group_key][8]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_8_squashed = {
    for group_key, group in local.range_8_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 8 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][8] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_9_with_sort_keys = {
    for group_key, group in local.range_8_squashed :
    group_key => length(local.range_keys[group_key]) <= 9 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][9]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][9]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][9]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][9]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][9]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][9]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][9]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][9]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][9]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][9]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_9_sort_keys = {
    for group_key, group in local.range_9_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 9 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_9_sorted = {
    for group_key, group in local.range_9_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 9 ? null : merge(group, {
      rules = [
        for sort_key in local.range_9_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_9_next_contiguous = {
    for group_key, group in local.range_9_sorted :
    group_key => length(local.range_keys[group_key]) <= 9 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][9]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][9]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][9]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][9]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][9]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][9]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][9] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_9_contiguous_forward_count = {
    for group_key, group in local.range_9_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 9 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_9_contiguous_base2 = {
    for group_key, group in local.range_9_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 9 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][9]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][9]].to_inclusive - rule.ranges[local.range_keys[group_key][9]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][9]].to_inclusive - rule.ranges[local.range_keys[group_key][9]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][9]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][9]].to_inclusive - rule.ranges[local.range_keys[group_key][9]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_9_squashed = {
    for group_key, group in local.range_9_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 9 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][9] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_10_with_sort_keys = {
    for group_key, group in local.range_9_squashed :
    group_key => length(local.range_keys[group_key]) <= 10 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][10]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][10]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][10]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][10]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][10]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][10]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][10]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][10]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][10]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][10]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_10_sort_keys = {
    for group_key, group in local.range_10_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 10 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_10_sorted = {
    for group_key, group in local.range_10_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 10 ? null : merge(group, {
      rules = [
        for sort_key in local.range_10_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_10_next_contiguous = {
    for group_key, group in local.range_10_sorted :
    group_key => length(local.range_keys[group_key]) <= 10 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][10]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][10]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][10]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][10]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][10]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][10]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][10] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_10_contiguous_forward_count = {
    for group_key, group in local.range_10_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 10 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_10_contiguous_base2 = {
    for group_key, group in local.range_10_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 10 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][10]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][10]].to_inclusive - rule.ranges[local.range_keys[group_key][10]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][10]].to_inclusive - rule.ranges[local.range_keys[group_key][10]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][10]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][10]].to_inclusive - rule.ranges[local.range_keys[group_key][10]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_10_squashed = {
    for group_key, group in local.range_10_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 10 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][10] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_11_with_sort_keys = {
    for group_key, group in local.range_10_squashed :
    group_key => length(local.range_keys[group_key]) <= 11 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][11]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][11]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][11]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][11]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][11]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][11]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][11]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][11]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][11]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][11]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_11_sort_keys = {
    for group_key, group in local.range_11_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 11 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_11_sorted = {
    for group_key, group in local.range_11_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 11 ? null : merge(group, {
      rules = [
        for sort_key in local.range_11_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_11_next_contiguous = {
    for group_key, group in local.range_11_sorted :
    group_key => length(local.range_keys[group_key]) <= 11 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][11]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][11]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][11]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][11]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][11]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][11]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][11] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_11_contiguous_forward_count = {
    for group_key, group in local.range_11_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 11 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_11_contiguous_base2 = {
    for group_key, group in local.range_11_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 11 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][11]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][11]].to_inclusive - rule.ranges[local.range_keys[group_key][11]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][11]].to_inclusive - rule.ranges[local.range_keys[group_key][11]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][11]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][11]].to_inclusive - rule.ranges[local.range_keys[group_key][11]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_11_squashed = {
    for group_key, group in local.range_11_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 11 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][11] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_12_with_sort_keys = {
    for group_key, group in local.range_11_squashed :
    group_key => length(local.range_keys[group_key]) <= 12 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][12]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][12]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][12]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][12]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][12]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][12]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][12]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][12]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][12]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][12]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_12_sort_keys = {
    for group_key, group in local.range_12_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 12 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_12_sorted = {
    for group_key, group in local.range_12_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 12 ? null : merge(group, {
      rules = [
        for sort_key in local.range_12_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_12_next_contiguous = {
    for group_key, group in local.range_12_sorted :
    group_key => length(local.range_keys[group_key]) <= 12 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][12]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][12]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][12]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][12]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][12]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][12]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][12] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_12_contiguous_forward_count = {
    for group_key, group in local.range_12_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 12 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_12_contiguous_base2 = {
    for group_key, group in local.range_12_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 12 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][12]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][12]].to_inclusive - rule.ranges[local.range_keys[group_key][12]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][12]].to_inclusive - rule.ranges[local.range_keys[group_key][12]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][12]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][12]].to_inclusive - rule.ranges[local.range_keys[group_key][12]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_12_squashed = {
    for group_key, group in local.range_12_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 12 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][12] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_13_with_sort_keys = {
    for group_key, group in local.range_12_squashed :
    group_key => length(local.range_keys[group_key]) <= 13 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][13]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][13]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][13]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][13]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][13]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][13]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][13]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][13]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][13]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][13]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_13_sort_keys = {
    for group_key, group in local.range_13_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 13 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_13_sorted = {
    for group_key, group in local.range_13_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 13 ? null : merge(group, {
      rules = [
        for sort_key in local.range_13_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_13_next_contiguous = {
    for group_key, group in local.range_13_sorted :
    group_key => length(local.range_keys[group_key]) <= 13 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][13]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][13]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][13]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][13]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][13]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][13]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][13] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_13_contiguous_forward_count = {
    for group_key, group in local.range_13_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 13 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_13_contiguous_base2 = {
    for group_key, group in local.range_13_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 13 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][13]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][13]].to_inclusive - rule.ranges[local.range_keys[group_key][13]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][13]].to_inclusive - rule.ranges[local.range_keys[group_key][13]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][13]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][13]].to_inclusive - rule.ranges[local.range_keys[group_key][13]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_13_squashed = {
    for group_key, group in local.range_13_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 13 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][13] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_14_with_sort_keys = {
    for group_key, group in local.range_13_squashed :
    group_key => length(local.range_keys[group_key]) <= 14 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][14]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][14]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][14]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][14]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][14]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][14]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][14]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][14]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][14]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][14]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_14_sort_keys = {
    for group_key, group in local.range_14_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 14 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_14_sorted = {
    for group_key, group in local.range_14_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 14 ? null : merge(group, {
      rules = [
        for sort_key in local.range_14_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_14_next_contiguous = {
    for group_key, group in local.range_14_sorted :
    group_key => length(local.range_keys[group_key]) <= 14 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][14]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][14]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][14]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][14]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][14]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][14]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][14] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_14_contiguous_forward_count = {
    for group_key, group in local.range_14_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 14 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_14_contiguous_base2 = {
    for group_key, group in local.range_14_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 14 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][14]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][14]].to_inclusive - rule.ranges[local.range_keys[group_key][14]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][14]].to_inclusive - rule.ranges[local.range_keys[group_key][14]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][14]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][14]].to_inclusive - rule.ranges[local.range_keys[group_key][14]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_14_squashed = {
    for group_key, group in local.range_14_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 14 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][14] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_15_with_sort_keys = {
    for group_key, group in local.range_14_squashed :
    group_key => length(local.range_keys[group_key]) <= 15 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][15]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][15]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][15]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][15]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][15]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][15]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][15]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][15]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][15]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][15]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_15_sort_keys = {
    for group_key, group in local.range_15_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 15 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_15_sorted = {
    for group_key, group in local.range_15_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 15 ? null : merge(group, {
      rules = [
        for sort_key in local.range_15_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_15_next_contiguous = {
    for group_key, group in local.range_15_sorted :
    group_key => length(local.range_keys[group_key]) <= 15 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][15]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][15]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][15]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][15]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][15]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][15]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][15] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_15_contiguous_forward_count = {
    for group_key, group in local.range_15_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 15 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_15_contiguous_base2 = {
    for group_key, group in local.range_15_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 15 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][15]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][15]].to_inclusive - rule.ranges[local.range_keys[group_key][15]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][15]].to_inclusive - rule.ranges[local.range_keys[group_key][15]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][15]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][15]].to_inclusive - rule.ranges[local.range_keys[group_key][15]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_15_squashed = {
    for group_key, group in local.range_15_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 15 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][15] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_16_with_sort_keys = {
    for group_key, group in local.range_15_squashed :
    group_key => length(local.range_keys[group_key]) <= 16 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][16]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][16]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][16]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][16]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][16]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][16]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][16]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][16]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][16]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][16]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_16_sort_keys = {
    for group_key, group in local.range_16_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 16 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_16_sorted = {
    for group_key, group in local.range_16_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 16 ? null : merge(group, {
      rules = [
        for sort_key in local.range_16_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_16_next_contiguous = {
    for group_key, group in local.range_16_sorted :
    group_key => length(local.range_keys[group_key]) <= 16 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][16]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][16]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][16]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][16]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][16]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][16]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][16] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_16_contiguous_forward_count = {
    for group_key, group in local.range_16_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 16 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_16_contiguous_base2 = {
    for group_key, group in local.range_16_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 16 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][16]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][16]].to_inclusive - rule.ranges[local.range_keys[group_key][16]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][16]].to_inclusive - rule.ranges[local.range_keys[group_key][16]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][16]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][16]].to_inclusive - rule.ranges[local.range_keys[group_key][16]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_16_squashed = {
    for group_key, group in local.range_16_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 16 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][16] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_17_with_sort_keys = {
    for group_key, group in local.range_16_squashed :
    group_key => length(local.range_keys[group_key]) <= 17 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][17]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][17]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][17]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][17]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][17]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][17]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][17]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][17]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][17]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][17]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_17_sort_keys = {
    for group_key, group in local.range_17_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 17 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_17_sorted = {
    for group_key, group in local.range_17_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 17 ? null : merge(group, {
      rules = [
        for sort_key in local.range_17_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_17_next_contiguous = {
    for group_key, group in local.range_17_sorted :
    group_key => length(local.range_keys[group_key]) <= 17 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][17]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][17]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][17]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][17]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][17]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][17]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][17] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_17_contiguous_forward_count = {
    for group_key, group in local.range_17_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 17 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_17_contiguous_base2 = {
    for group_key, group in local.range_17_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 17 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][17]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][17]].to_inclusive - rule.ranges[local.range_keys[group_key][17]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][17]].to_inclusive - rule.ranges[local.range_keys[group_key][17]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][17]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][17]].to_inclusive - rule.ranges[local.range_keys[group_key][17]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_17_squashed = {
    for group_key, group in local.range_17_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 17 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][17] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_18_with_sort_keys = {
    for group_key, group in local.range_17_squashed :
    group_key => length(local.range_keys[group_key]) <= 18 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][18]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][18]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][18]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][18]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][18]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][18]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][18]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][18]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][18]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][18]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_18_sort_keys = {
    for group_key, group in local.range_18_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 18 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_18_sorted = {
    for group_key, group in local.range_18_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 18 ? null : merge(group, {
      rules = [
        for sort_key in local.range_18_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_18_next_contiguous = {
    for group_key, group in local.range_18_sorted :
    group_key => length(local.range_keys[group_key]) <= 18 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][18]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][18]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][18]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][18]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][18]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][18]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][18] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_18_contiguous_forward_count = {
    for group_key, group in local.range_18_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 18 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_18_contiguous_base2 = {
    for group_key, group in local.range_18_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 18 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][18]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][18]].to_inclusive - rule.ranges[local.range_keys[group_key][18]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][18]].to_inclusive - rule.ranges[local.range_keys[group_key][18]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][18]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][18]].to_inclusive - rule.ranges[local.range_keys[group_key][18]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_18_squashed = {
    for group_key, group in local.range_18_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 18 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][18] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_19_with_sort_keys = {
    for group_key, group in local.range_18_squashed :
    group_key => length(local.range_keys[group_key]) <= 19 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][19]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][19]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][19]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][19]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][19]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][19]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][19]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][19]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][19]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][19]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_19_sort_keys = {
    for group_key, group in local.range_19_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 19 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_19_sorted = {
    for group_key, group in local.range_19_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 19 ? null : merge(group, {
      rules = [
        for sort_key in local.range_19_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_19_next_contiguous = {
    for group_key, group in local.range_19_sorted :
    group_key => length(local.range_keys[group_key]) <= 19 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][19]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][19]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][19]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][19]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][19]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][19]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][19] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_19_contiguous_forward_count = {
    for group_key, group in local.range_19_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 19 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_19_contiguous_base2 = {
    for group_key, group in local.range_19_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 19 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][19]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][19]].to_inclusive - rule.ranges[local.range_keys[group_key][19]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][19]].to_inclusive - rule.ranges[local.range_keys[group_key][19]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][19]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][19]].to_inclusive - rule.ranges[local.range_keys[group_key][19]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_19_squashed = {
    for group_key, group in local.range_19_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 19 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][19] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_20_with_sort_keys = {
    for group_key, group in local.range_19_squashed :
    group_key => length(local.range_keys[group_key]) <= 20 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][20]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][20]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][20]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][20]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][20]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][20]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][20]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][20]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][20]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][20]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_20_sort_keys = {
    for group_key, group in local.range_20_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 20 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_20_sorted = {
    for group_key, group in local.range_20_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 20 ? null : merge(group, {
      rules = [
        for sort_key in local.range_20_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_20_next_contiguous = {
    for group_key, group in local.range_20_sorted :
    group_key => length(local.range_keys[group_key]) <= 20 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][20]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][20]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][20]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][20]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][20]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][20]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][20] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_20_contiguous_forward_count = {
    for group_key, group in local.range_20_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 20 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_20_contiguous_base2 = {
    for group_key, group in local.range_20_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 20 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][20]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][20]].to_inclusive - rule.ranges[local.range_keys[group_key][20]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][20]].to_inclusive - rule.ranges[local.range_keys[group_key][20]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][20]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][20]].to_inclusive - rule.ranges[local.range_keys[group_key][20]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_20_squashed = {
    for group_key, group in local.range_20_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 20 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][20] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_21_with_sort_keys = {
    for group_key, group in local.range_20_squashed :
    group_key => length(local.range_keys[group_key]) <= 21 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][21]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][21]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][21]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][21]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][21]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][21]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][21]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][21]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][21]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][21]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_21_sort_keys = {
    for group_key, group in local.range_21_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 21 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_21_sorted = {
    for group_key, group in local.range_21_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 21 ? null : merge(group, {
      rules = [
        for sort_key in local.range_21_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_21_next_contiguous = {
    for group_key, group in local.range_21_sorted :
    group_key => length(local.range_keys[group_key]) <= 21 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][21]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][21]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][21]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][21]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][21]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][21]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][21] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_21_contiguous_forward_count = {
    for group_key, group in local.range_21_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 21 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_21_contiguous_base2 = {
    for group_key, group in local.range_21_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 21 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][21]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][21]].to_inclusive - rule.ranges[local.range_keys[group_key][21]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][21]].to_inclusive - rule.ranges[local.range_keys[group_key][21]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][21]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][21]].to_inclusive - rule.ranges[local.range_keys[group_key][21]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_21_squashed = {
    for group_key, group in local.range_21_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 21 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][21] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_22_with_sort_keys = {
    for group_key, group in local.range_21_squashed :
    group_key => length(local.range_keys[group_key]) <= 22 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][22]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][22]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][22]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][22]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][22]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][22]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][22]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][22]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][22]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][22]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_22_sort_keys = {
    for group_key, group in local.range_22_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 22 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_22_sorted = {
    for group_key, group in local.range_22_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 22 ? null : merge(group, {
      rules = [
        for sort_key in local.range_22_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_22_next_contiguous = {
    for group_key, group in local.range_22_sorted :
    group_key => length(local.range_keys[group_key]) <= 22 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][22]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][22]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][22]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][22]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][22]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][22]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][22] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_22_contiguous_forward_count = {
    for group_key, group in local.range_22_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 22 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_22_contiguous_base2 = {
    for group_key, group in local.range_22_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 22 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][22]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][22]].to_inclusive - rule.ranges[local.range_keys[group_key][22]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][22]].to_inclusive - rule.ranges[local.range_keys[group_key][22]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][22]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][22]].to_inclusive - rule.ranges[local.range_keys[group_key][22]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_22_squashed = {
    for group_key, group in local.range_22_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 22 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][22] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_23_with_sort_keys = {
    for group_key, group in local.range_22_squashed :
    group_key => length(local.range_keys[group_key]) <= 23 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][23]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][23]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][23]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][23]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][23]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][23]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][23]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][23]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][23]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][23]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_23_sort_keys = {
    for group_key, group in local.range_23_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 23 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_23_sorted = {
    for group_key, group in local.range_23_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 23 ? null : merge(group, {
      rules = [
        for sort_key in local.range_23_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_23_next_contiguous = {
    for group_key, group in local.range_23_sorted :
    group_key => length(local.range_keys[group_key]) <= 23 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][23]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][23]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][23]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][23]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][23]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][23]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][23] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_23_contiguous_forward_count = {
    for group_key, group in local.range_23_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 23 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_23_contiguous_base2 = {
    for group_key, group in local.range_23_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 23 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][23]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][23]].to_inclusive - rule.ranges[local.range_keys[group_key][23]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][23]].to_inclusive - rule.ranges[local.range_keys[group_key][23]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][23]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][23]].to_inclusive - rule.ranges[local.range_keys[group_key][23]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_23_squashed = {
    for group_key, group in local.range_23_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 23 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][23] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_24_with_sort_keys = {
    for group_key, group in local.range_23_squashed :
    group_key => length(local.range_keys[group_key]) <= 24 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][24]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][24]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][24]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][24]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][24]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][24]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][24]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][24]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][24]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][24]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_24_sort_keys = {
    for group_key, group in local.range_24_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 24 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_24_sorted = {
    for group_key, group in local.range_24_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 24 ? null : merge(group, {
      rules = [
        for sort_key in local.range_24_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_24_next_contiguous = {
    for group_key, group in local.range_24_sorted :
    group_key => length(local.range_keys[group_key]) <= 24 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][24]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][24]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][24]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][24]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][24]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][24]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][24] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_24_contiguous_forward_count = {
    for group_key, group in local.range_24_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 24 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_24_contiguous_base2 = {
    for group_key, group in local.range_24_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 24 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][24]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][24]].to_inclusive - rule.ranges[local.range_keys[group_key][24]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][24]].to_inclusive - rule.ranges[local.range_keys[group_key][24]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][24]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][24]].to_inclusive - rule.ranges[local.range_keys[group_key][24]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_24_squashed = {
    for group_key, group in local.range_24_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 24 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][24] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_25_with_sort_keys = {
    for group_key, group in local.range_24_squashed :
    group_key => length(local.range_keys[group_key]) <= 25 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][25]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][25]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][25]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][25]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][25]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][25]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][25]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][25]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][25]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][25]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_25_sort_keys = {
    for group_key, group in local.range_25_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 25 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_25_sorted = {
    for group_key, group in local.range_25_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 25 ? null : merge(group, {
      rules = [
        for sort_key in local.range_25_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_25_next_contiguous = {
    for group_key, group in local.range_25_sorted :
    group_key => length(local.range_keys[group_key]) <= 25 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][25]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][25]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][25]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][25]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][25]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][25]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][25] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_25_contiguous_forward_count = {
    for group_key, group in local.range_25_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 25 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_25_contiguous_base2 = {
    for group_key, group in local.range_25_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 25 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][25]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][25]].to_inclusive - rule.ranges[local.range_keys[group_key][25]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][25]].to_inclusive - rule.ranges[local.range_keys[group_key][25]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][25]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][25]].to_inclusive - rule.ranges[local.range_keys[group_key][25]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_25_squashed = {
    for group_key, group in local.range_25_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 25 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][25] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_26_with_sort_keys = {
    for group_key, group in local.range_25_squashed :
    group_key => length(local.range_keys[group_key]) <= 26 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][26]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][26]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][26]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][26]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][26]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][26]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][26]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][26]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][26]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][26]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_26_sort_keys = {
    for group_key, group in local.range_26_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 26 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_26_sorted = {
    for group_key, group in local.range_26_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 26 ? null : merge(group, {
      rules = [
        for sort_key in local.range_26_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_26_next_contiguous = {
    for group_key, group in local.range_26_sorted :
    group_key => length(local.range_keys[group_key]) <= 26 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][26]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][26]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][26]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][26]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][26]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][26]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][26] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_26_contiguous_forward_count = {
    for group_key, group in local.range_26_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 26 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_26_contiguous_base2 = {
    for group_key, group in local.range_26_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 26 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][26]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][26]].to_inclusive - rule.ranges[local.range_keys[group_key][26]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][26]].to_inclusive - rule.ranges[local.range_keys[group_key][26]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][26]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][26]].to_inclusive - rule.ranges[local.range_keys[group_key][26]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_26_squashed = {
    for group_key, group in local.range_26_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 26 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][26] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_27_with_sort_keys = {
    for group_key, group in local.range_26_squashed :
    group_key => length(local.range_keys[group_key]) <= 27 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][27]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][27]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][27]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][27]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][27]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][27]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][27]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][27]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][27]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][27]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_27_sort_keys = {
    for group_key, group in local.range_27_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 27 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_27_sorted = {
    for group_key, group in local.range_27_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 27 ? null : merge(group, {
      rules = [
        for sort_key in local.range_27_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_27_next_contiguous = {
    for group_key, group in local.range_27_sorted :
    group_key => length(local.range_keys[group_key]) <= 27 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][27]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][27]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][27]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][27]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][27]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][27]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][27] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_27_contiguous_forward_count = {
    for group_key, group in local.range_27_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 27 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_27_contiguous_base2 = {
    for group_key, group in local.range_27_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 27 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][27]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][27]].to_inclusive - rule.ranges[local.range_keys[group_key][27]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][27]].to_inclusive - rule.ranges[local.range_keys[group_key][27]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][27]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][27]].to_inclusive - rule.ranges[local.range_keys[group_key][27]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_27_squashed = {
    for group_key, group in local.range_27_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 27 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][27] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_28_with_sort_keys = {
    for group_key, group in local.range_27_squashed :
    group_key => length(local.range_keys[group_key]) <= 28 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][28]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][28]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][28]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][28]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][28]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][28]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][28]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][28]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][28]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][28]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_28_sort_keys = {
    for group_key, group in local.range_28_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 28 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_28_sorted = {
    for group_key, group in local.range_28_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 28 ? null : merge(group, {
      rules = [
        for sort_key in local.range_28_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_28_next_contiguous = {
    for group_key, group in local.range_28_sorted :
    group_key => length(local.range_keys[group_key]) <= 28 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][28]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][28]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][28]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][28]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][28]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][28]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][28] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_28_contiguous_forward_count = {
    for group_key, group in local.range_28_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 28 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_28_contiguous_base2 = {
    for group_key, group in local.range_28_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 28 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][28]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][28]].to_inclusive - rule.ranges[local.range_keys[group_key][28]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][28]].to_inclusive - rule.ranges[local.range_keys[group_key][28]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][28]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][28]].to_inclusive - rule.ranges[local.range_keys[group_key][28]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_28_squashed = {
    for group_key, group in local.range_28_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 28 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][28] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_29_with_sort_keys = {
    for group_key, group in local.range_28_squashed :
    group_key => length(local.range_keys[group_key]) <= 29 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][29]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][29]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][29]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][29]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][29]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][29]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][29]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][29]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][29]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][29]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_29_sort_keys = {
    for group_key, group in local.range_29_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 29 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_29_sorted = {
    for group_key, group in local.range_29_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 29 ? null : merge(group, {
      rules = [
        for sort_key in local.range_29_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_29_next_contiguous = {
    for group_key, group in local.range_29_sorted :
    group_key => length(local.range_keys[group_key]) <= 29 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][29]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][29]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][29]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][29]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][29]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][29]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][29] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_29_contiguous_forward_count = {
    for group_key, group in local.range_29_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 29 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_29_contiguous_base2 = {
    for group_key, group in local.range_29_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 29 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][29]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][29]].to_inclusive - rule.ranges[local.range_keys[group_key][29]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][29]].to_inclusive - rule.ranges[local.range_keys[group_key][29]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][29]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][29]].to_inclusive - rule.ranges[local.range_keys[group_key][29]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_29_squashed = {
    for group_key, group in local.range_29_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 29 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][29] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_30_with_sort_keys = {
    for group_key, group in local.range_29_squashed :
    group_key => length(local.range_keys[group_key]) <= 30 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][30]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][30]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][30]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][30]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][30]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][30]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][30]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][30]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][30]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][30]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_30_sort_keys = {
    for group_key, group in local.range_30_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 30 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_30_sorted = {
    for group_key, group in local.range_30_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 30 ? null : merge(group, {
      rules = [
        for sort_key in local.range_30_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_30_next_contiguous = {
    for group_key, group in local.range_30_sorted :
    group_key => length(local.range_keys[group_key]) <= 30 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][30]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][30]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][30]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][30]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][30]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][30]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][30] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_30_contiguous_forward_count = {
    for group_key, group in local.range_30_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 30 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_30_contiguous_base2 = {
    for group_key, group in local.range_30_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 30 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][30]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][30]].to_inclusive - rule.ranges[local.range_keys[group_key][30]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][30]].to_inclusive - rule.ranges[local.range_keys[group_key][30]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][30]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][30]].to_inclusive - rule.ranges[local.range_keys[group_key][30]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_30_squashed = {
    for group_key, group in local.range_30_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 30 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][30] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_31_with_sort_keys = {
    for group_key, group in local.range_30_squashed :
    group_key => length(local.range_keys[group_key]) <= 31 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][31]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][31]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][31]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][31]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][31]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][31]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][31]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][31]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][31]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][31]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_31_sort_keys = {
    for group_key, group in local.range_31_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 31 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_31_sorted = {
    for group_key, group in local.range_31_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 31 ? null : merge(group, {
      rules = [
        for sort_key in local.range_31_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_31_next_contiguous = {
    for group_key, group in local.range_31_sorted :
    group_key => length(local.range_keys[group_key]) <= 31 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][31]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][31]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][31]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][31]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][31]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][31]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][31] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_31_contiguous_forward_count = {
    for group_key, group in local.range_31_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 31 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_31_contiguous_base2 = {
    for group_key, group in local.range_31_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 31 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][31]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][31]].to_inclusive - rule.ranges[local.range_keys[group_key][31]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][31]].to_inclusive - rule.ranges[local.range_keys[group_key][31]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][31]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][31]].to_inclusive - rule.ranges[local.range_keys[group_key][31]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_31_squashed = {
    for group_key, group in local.range_31_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 31 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][31] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_32_with_sort_keys = {
    for group_key, group in local.range_31_squashed :
    group_key => length(local.range_keys[group_key]) <= 32 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][32]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][32]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][32]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][32]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][32]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][32]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][32]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][32]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][32]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][32]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_32_sort_keys = {
    for group_key, group in local.range_32_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 32 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_32_sorted = {
    for group_key, group in local.range_32_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 32 ? null : merge(group, {
      rules = [
        for sort_key in local.range_32_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_32_next_contiguous = {
    for group_key, group in local.range_32_sorted :
    group_key => length(local.range_keys[group_key]) <= 32 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][32]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][32]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][32]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][32]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][32]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][32]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][32] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_32_contiguous_forward_count = {
    for group_key, group in local.range_32_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 32 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_32_contiguous_base2 = {
    for group_key, group in local.range_32_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 32 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][32]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][32]].to_inclusive - rule.ranges[local.range_keys[group_key][32]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][32]].to_inclusive - rule.ranges[local.range_keys[group_key][32]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][32]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][32]].to_inclusive - rule.ranges[local.range_keys[group_key][32]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_32_squashed = {
    for group_key, group in local.range_32_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 32 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][32] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_33_with_sort_keys = {
    for group_key, group in local.range_32_squashed :
    group_key => length(local.range_keys[group_key]) <= 33 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][33]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][33]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][33]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][33]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][33]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][33]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][33]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][33]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][33]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][33]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_33_sort_keys = {
    for group_key, group in local.range_33_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 33 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_33_sorted = {
    for group_key, group in local.range_33_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 33 ? null : merge(group, {
      rules = [
        for sort_key in local.range_33_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_33_next_contiguous = {
    for group_key, group in local.range_33_sorted :
    group_key => length(local.range_keys[group_key]) <= 33 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][33]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][33]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][33]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][33]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][33]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][33]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][33] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_33_contiguous_forward_count = {
    for group_key, group in local.range_33_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 33 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_33_contiguous_base2 = {
    for group_key, group in local.range_33_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 33 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][33]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][33]].to_inclusive - rule.ranges[local.range_keys[group_key][33]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][33]].to_inclusive - rule.ranges[local.range_keys[group_key][33]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][33]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][33]].to_inclusive - rule.ranges[local.range_keys[group_key][33]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_33_squashed = {
    for group_key, group in local.range_33_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 33 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][33] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_34_with_sort_keys = {
    for group_key, group in local.range_33_squashed :
    group_key => length(local.range_keys[group_key]) <= 34 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][34]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][34]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][34]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][34]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][34]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][34]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][34]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][34]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][34]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][34]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_34_sort_keys = {
    for group_key, group in local.range_34_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 34 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_34_sorted = {
    for group_key, group in local.range_34_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 34 ? null : merge(group, {
      rules = [
        for sort_key in local.range_34_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_34_next_contiguous = {
    for group_key, group in local.range_34_sorted :
    group_key => length(local.range_keys[group_key]) <= 34 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][34]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][34]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][34]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][34]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][34]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][34]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][34] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_34_contiguous_forward_count = {
    for group_key, group in local.range_34_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 34 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_34_contiguous_base2 = {
    for group_key, group in local.range_34_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 34 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][34]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][34]].to_inclusive - rule.ranges[local.range_keys[group_key][34]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][34]].to_inclusive - rule.ranges[local.range_keys[group_key][34]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][34]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][34]].to_inclusive - rule.ranges[local.range_keys[group_key][34]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_34_squashed = {
    for group_key, group in local.range_34_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 34 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][34] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_35_with_sort_keys = {
    for group_key, group in local.range_34_squashed :
    group_key => length(local.range_keys[group_key]) <= 35 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][35]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][35]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][35]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][35]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][35]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][35]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][35]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][35]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][35]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][35]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_35_sort_keys = {
    for group_key, group in local.range_35_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 35 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_35_sorted = {
    for group_key, group in local.range_35_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 35 ? null : merge(group, {
      rules = [
        for sort_key in local.range_35_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_35_next_contiguous = {
    for group_key, group in local.range_35_sorted :
    group_key => length(local.range_keys[group_key]) <= 35 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][35]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][35]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][35]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][35]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][35]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][35]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][35] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_35_contiguous_forward_count = {
    for group_key, group in local.range_35_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 35 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_35_contiguous_base2 = {
    for group_key, group in local.range_35_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 35 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][35]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][35]].to_inclusive - rule.ranges[local.range_keys[group_key][35]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][35]].to_inclusive - rule.ranges[local.range_keys[group_key][35]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][35]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][35]].to_inclusive - rule.ranges[local.range_keys[group_key][35]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_35_squashed = {
    for group_key, group in local.range_35_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 35 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][35] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_36_with_sort_keys = {
    for group_key, group in local.range_35_squashed :
    group_key => length(local.range_keys[group_key]) <= 36 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][36]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][36]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][36]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][36]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][36]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][36]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][36]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][36]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][36]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][36]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_36_sort_keys = {
    for group_key, group in local.range_36_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 36 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_36_sorted = {
    for group_key, group in local.range_36_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 36 ? null : merge(group, {
      rules = [
        for sort_key in local.range_36_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_36_next_contiguous = {
    for group_key, group in local.range_36_sorted :
    group_key => length(local.range_keys[group_key]) <= 36 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][36]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][36]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][36]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][36]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][36]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][36]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][36] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_36_contiguous_forward_count = {
    for group_key, group in local.range_36_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 36 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_36_contiguous_base2 = {
    for group_key, group in local.range_36_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 36 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][36]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][36]].to_inclusive - rule.ranges[local.range_keys[group_key][36]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][36]].to_inclusive - rule.ranges[local.range_keys[group_key][36]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][36]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][36]].to_inclusive - rule.ranges[local.range_keys[group_key][36]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_36_squashed = {
    for group_key, group in local.range_36_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 36 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][36] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_37_with_sort_keys = {
    for group_key, group in local.range_36_squashed :
    group_key => length(local.range_keys[group_key]) <= 37 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][37]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][37]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][37]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][37]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][37]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][37]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][37]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][37]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][37]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][37]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_37_sort_keys = {
    for group_key, group in local.range_37_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 37 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_37_sorted = {
    for group_key, group in local.range_37_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 37 ? null : merge(group, {
      rules = [
        for sort_key in local.range_37_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_37_next_contiguous = {
    for group_key, group in local.range_37_sorted :
    group_key => length(local.range_keys[group_key]) <= 37 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][37]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][37]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][37]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][37]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][37]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][37]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][37] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_37_contiguous_forward_count = {
    for group_key, group in local.range_37_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 37 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_37_contiguous_base2 = {
    for group_key, group in local.range_37_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 37 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][37]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][37]].to_inclusive - rule.ranges[local.range_keys[group_key][37]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][37]].to_inclusive - rule.ranges[local.range_keys[group_key][37]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][37]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][37]].to_inclusive - rule.ranges[local.range_keys[group_key][37]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_37_squashed = {
    for group_key, group in local.range_37_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 37 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][37] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_38_with_sort_keys = {
    for group_key, group in local.range_37_squashed :
    group_key => length(local.range_keys[group_key]) <= 38 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][38]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][38]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][38]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][38]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][38]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][38]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][38]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][38]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][38]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][38]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_38_sort_keys = {
    for group_key, group in local.range_38_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 38 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_38_sorted = {
    for group_key, group in local.range_38_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 38 ? null : merge(group, {
      rules = [
        for sort_key in local.range_38_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_38_next_contiguous = {
    for group_key, group in local.range_38_sorted :
    group_key => length(local.range_keys[group_key]) <= 38 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][38]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][38]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][38]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][38]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][38]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][38]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][38] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_38_contiguous_forward_count = {
    for group_key, group in local.range_38_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 38 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_38_contiguous_base2 = {
    for group_key, group in local.range_38_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 38 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][38]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][38]].to_inclusive - rule.ranges[local.range_keys[group_key][38]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][38]].to_inclusive - rule.ranges[local.range_keys[group_key][38]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][38]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][38]].to_inclusive - rule.ranges[local.range_keys[group_key][38]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_38_squashed = {
    for group_key, group in local.range_38_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 38 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][38] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_39_with_sort_keys = {
    for group_key, group in local.range_38_squashed :
    group_key => length(local.range_keys[group_key]) <= 39 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][39]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][39]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][39]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][39]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][39]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][39]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][39]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][39]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][39]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][39]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_39_sort_keys = {
    for group_key, group in local.range_39_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 39 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_39_sorted = {
    for group_key, group in local.range_39_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 39 ? null : merge(group, {
      rules = [
        for sort_key in local.range_39_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_39_next_contiguous = {
    for group_key, group in local.range_39_sorted :
    group_key => length(local.range_keys[group_key]) <= 39 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][39]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][39]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][39]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][39]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][39]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][39]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][39] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_39_contiguous_forward_count = {
    for group_key, group in local.range_39_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 39 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_39_contiguous_base2 = {
    for group_key, group in local.range_39_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 39 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][39]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][39]].to_inclusive - rule.ranges[local.range_keys[group_key][39]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][39]].to_inclusive - rule.ranges[local.range_keys[group_key][39]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][39]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][39]].to_inclusive - rule.ranges[local.range_keys[group_key][39]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_39_squashed = {
    for group_key, group in local.range_39_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 39 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][39] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_40_with_sort_keys = {
    for group_key, group in local.range_39_squashed :
    group_key => length(local.range_keys[group_key]) <= 40 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][40]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][40]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][40]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][40]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][40]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][40]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][40]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][40]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][40]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][40]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_40_sort_keys = {
    for group_key, group in local.range_40_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 40 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_40_sorted = {
    for group_key, group in local.range_40_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 40 ? null : merge(group, {
      rules = [
        for sort_key in local.range_40_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_40_next_contiguous = {
    for group_key, group in local.range_40_sorted :
    group_key => length(local.range_keys[group_key]) <= 40 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][40]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][40]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][40]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][40]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][40]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][40]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][40] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_40_contiguous_forward_count = {
    for group_key, group in local.range_40_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 40 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_40_contiguous_base2 = {
    for group_key, group in local.range_40_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 40 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][40]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][40]].to_inclusive - rule.ranges[local.range_keys[group_key][40]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][40]].to_inclusive - rule.ranges[local.range_keys[group_key][40]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][40]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][40]].to_inclusive - rule.ranges[local.range_keys[group_key][40]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_40_squashed = {
    for group_key, group in local.range_40_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 40 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][40] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_41_with_sort_keys = {
    for group_key, group in local.range_40_squashed :
    group_key => length(local.range_keys[group_key]) <= 41 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][41]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][41]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][41]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][41]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][41]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][41]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][41]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][41]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][41]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][41]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_41_sort_keys = {
    for group_key, group in local.range_41_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 41 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_41_sorted = {
    for group_key, group in local.range_41_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 41 ? null : merge(group, {
      rules = [
        for sort_key in local.range_41_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_41_next_contiguous = {
    for group_key, group in local.range_41_sorted :
    group_key => length(local.range_keys[group_key]) <= 41 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][41]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][41]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][41]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][41]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][41]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][41]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][41] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_41_contiguous_forward_count = {
    for group_key, group in local.range_41_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 41 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_41_contiguous_base2 = {
    for group_key, group in local.range_41_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 41 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][41]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][41]].to_inclusive - rule.ranges[local.range_keys[group_key][41]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][41]].to_inclusive - rule.ranges[local.range_keys[group_key][41]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][41]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][41]].to_inclusive - rule.ranges[local.range_keys[group_key][41]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_41_squashed = {
    for group_key, group in local.range_41_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 41 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][41] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_42_with_sort_keys = {
    for group_key, group in local.range_41_squashed :
    group_key => length(local.range_keys[group_key]) <= 42 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][42]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][42]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][42]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][42]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][42]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][42]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][42]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][42]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][42]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][42]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_42_sort_keys = {
    for group_key, group in local.range_42_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 42 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_42_sorted = {
    for group_key, group in local.range_42_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 42 ? null : merge(group, {
      rules = [
        for sort_key in local.range_42_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_42_next_contiguous = {
    for group_key, group in local.range_42_sorted :
    group_key => length(local.range_keys[group_key]) <= 42 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][42]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][42]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][42]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][42]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][42]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][42]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][42] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_42_contiguous_forward_count = {
    for group_key, group in local.range_42_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 42 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_42_contiguous_base2 = {
    for group_key, group in local.range_42_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 42 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][42]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][42]].to_inclusive - rule.ranges[local.range_keys[group_key][42]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][42]].to_inclusive - rule.ranges[local.range_keys[group_key][42]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][42]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][42]].to_inclusive - rule.ranges[local.range_keys[group_key][42]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_42_squashed = {
    for group_key, group in local.range_42_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 42 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][42] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_43_with_sort_keys = {
    for group_key, group in local.range_42_squashed :
    group_key => length(local.range_keys[group_key]) <= 43 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][43]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][43]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][43]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][43]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][43]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][43]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][43]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][43]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][43]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][43]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_43_sort_keys = {
    for group_key, group in local.range_43_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 43 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_43_sorted = {
    for group_key, group in local.range_43_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 43 ? null : merge(group, {
      rules = [
        for sort_key in local.range_43_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_43_next_contiguous = {
    for group_key, group in local.range_43_sorted :
    group_key => length(local.range_keys[group_key]) <= 43 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][43]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][43]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][43]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][43]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][43]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][43]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][43] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_43_contiguous_forward_count = {
    for group_key, group in local.range_43_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 43 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_43_contiguous_base2 = {
    for group_key, group in local.range_43_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 43 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][43]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][43]].to_inclusive - rule.ranges[local.range_keys[group_key][43]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][43]].to_inclusive - rule.ranges[local.range_keys[group_key][43]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][43]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][43]].to_inclusive - rule.ranges[local.range_keys[group_key][43]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_43_squashed = {
    for group_key, group in local.range_43_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 43 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][43] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_44_with_sort_keys = {
    for group_key, group in local.range_43_squashed :
    group_key => length(local.range_keys[group_key]) <= 44 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][44]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][44]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][44]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][44]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][44]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][44]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][44]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][44]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][44]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][44]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_44_sort_keys = {
    for group_key, group in local.range_44_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 44 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_44_sorted = {
    for group_key, group in local.range_44_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 44 ? null : merge(group, {
      rules = [
        for sort_key in local.range_44_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_44_next_contiguous = {
    for group_key, group in local.range_44_sorted :
    group_key => length(local.range_keys[group_key]) <= 44 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][44]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][44]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][44]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][44]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][44]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][44]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][44] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_44_contiguous_forward_count = {
    for group_key, group in local.range_44_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 44 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_44_contiguous_base2 = {
    for group_key, group in local.range_44_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 44 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][44]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][44]].to_inclusive - rule.ranges[local.range_keys[group_key][44]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][44]].to_inclusive - rule.ranges[local.range_keys[group_key][44]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][44]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][44]].to_inclusive - rule.ranges[local.range_keys[group_key][44]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_44_squashed = {
    for group_key, group in local.range_44_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 44 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][44] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_45_with_sort_keys = {
    for group_key, group in local.range_44_squashed :
    group_key => length(local.range_keys[group_key]) <= 45 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][45]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][45]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][45]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][45]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][45]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][45]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][45]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][45]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][45]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][45]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_45_sort_keys = {
    for group_key, group in local.range_45_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 45 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_45_sorted = {
    for group_key, group in local.range_45_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 45 ? null : merge(group, {
      rules = [
        for sort_key in local.range_45_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_45_next_contiguous = {
    for group_key, group in local.range_45_sorted :
    group_key => length(local.range_keys[group_key]) <= 45 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][45]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][45]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][45]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][45]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][45]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][45]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][45] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_45_contiguous_forward_count = {
    for group_key, group in local.range_45_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 45 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_45_contiguous_base2 = {
    for group_key, group in local.range_45_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 45 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][45]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][45]].to_inclusive - rule.ranges[local.range_keys[group_key][45]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][45]].to_inclusive - rule.ranges[local.range_keys[group_key][45]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][45]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][45]].to_inclusive - rule.ranges[local.range_keys[group_key][45]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_45_squashed = {
    for group_key, group in local.range_45_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 45 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][45] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_46_with_sort_keys = {
    for group_key, group in local.range_45_squashed :
    group_key => length(local.range_keys[group_key]) <= 46 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][46]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][46]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][46]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][46]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][46]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][46]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][46]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][46]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][46]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][46]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_46_sort_keys = {
    for group_key, group in local.range_46_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 46 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_46_sorted = {
    for group_key, group in local.range_46_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 46 ? null : merge(group, {
      rules = [
        for sort_key in local.range_46_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_46_next_contiguous = {
    for group_key, group in local.range_46_sorted :
    group_key => length(local.range_keys[group_key]) <= 46 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][46]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][46]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][46]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][46]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][46]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][46]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][46] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_46_contiguous_forward_count = {
    for group_key, group in local.range_46_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 46 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_46_contiguous_base2 = {
    for group_key, group in local.range_46_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 46 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][46]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][46]].to_inclusive - rule.ranges[local.range_keys[group_key][46]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][46]].to_inclusive - rule.ranges[local.range_keys[group_key][46]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][46]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][46]].to_inclusive - rule.ranges[local.range_keys[group_key][46]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_46_squashed = {
    for group_key, group in local.range_46_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 46 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][46] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_47_with_sort_keys = {
    for group_key, group in local.range_46_squashed :
    group_key => length(local.range_keys[group_key]) <= 47 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][47]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][47]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][47]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][47]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][47]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][47]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][47]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][47]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][47]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][47]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_47_sort_keys = {
    for group_key, group in local.range_47_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 47 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_47_sorted = {
    for group_key, group in local.range_47_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 47 ? null : merge(group, {
      rules = [
        for sort_key in local.range_47_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_47_next_contiguous = {
    for group_key, group in local.range_47_sorted :
    group_key => length(local.range_keys[group_key]) <= 47 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][47]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][47]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][47]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][47]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][47]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][47]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][47] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_47_contiguous_forward_count = {
    for group_key, group in local.range_47_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 47 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_47_contiguous_base2 = {
    for group_key, group in local.range_47_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 47 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][47]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][47]].to_inclusive - rule.ranges[local.range_keys[group_key][47]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][47]].to_inclusive - rule.ranges[local.range_keys[group_key][47]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][47]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][47]].to_inclusive - rule.ranges[local.range_keys[group_key][47]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_47_squashed = {
    for group_key, group in local.range_47_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 47 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][47] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_48_with_sort_keys = {
    for group_key, group in local.range_47_squashed :
    group_key => length(local.range_keys[group_key]) <= 48 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][48]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][48]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][48]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][48]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][48]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][48]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][48]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][48]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][48]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][48]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_48_sort_keys = {
    for group_key, group in local.range_48_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 48 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_48_sorted = {
    for group_key, group in local.range_48_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 48 ? null : merge(group, {
      rules = [
        for sort_key in local.range_48_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_48_next_contiguous = {
    for group_key, group in local.range_48_sorted :
    group_key => length(local.range_keys[group_key]) <= 48 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][48]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][48]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][48]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][48]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][48]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][48]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][48] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_48_contiguous_forward_count = {
    for group_key, group in local.range_48_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 48 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_48_contiguous_base2 = {
    for group_key, group in local.range_48_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 48 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][48]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][48]].to_inclusive - rule.ranges[local.range_keys[group_key][48]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][48]].to_inclusive - rule.ranges[local.range_keys[group_key][48]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][48]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][48]].to_inclusive - rule.ranges[local.range_keys[group_key][48]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_48_squashed = {
    for group_key, group in local.range_48_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 48 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][48] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_49_with_sort_keys = {
    for group_key, group in local.range_48_squashed :
    group_key => length(local.range_keys[group_key]) <= 49 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][49]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][49]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][49]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][49]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][49]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][49]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][49]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][49]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][49]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][49]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_49_sort_keys = {
    for group_key, group in local.range_49_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 49 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_49_sorted = {
    for group_key, group in local.range_49_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 49 ? null : merge(group, {
      rules = [
        for sort_key in local.range_49_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_49_next_contiguous = {
    for group_key, group in local.range_49_sorted :
    group_key => length(local.range_keys[group_key]) <= 49 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][49]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][49]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][49]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][49]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][49]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][49]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][49] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_49_contiguous_forward_count = {
    for group_key, group in local.range_49_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 49 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_49_contiguous_base2 = {
    for group_key, group in local.range_49_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 49 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][49]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][49]].to_inclusive - rule.ranges[local.range_keys[group_key][49]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][49]].to_inclusive - rule.ranges[local.range_keys[group_key][49]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][49]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][49]].to_inclusive - rule.ranges[local.range_keys[group_key][49]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_49_squashed = {
    for group_key, group in local.range_49_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 49 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][49] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_50_with_sort_keys = {
    for group_key, group in local.range_49_squashed :
    group_key => length(local.range_keys[group_key]) <= 50 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][50]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][50]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][50]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][50]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][50]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][50]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][50]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][50]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][50]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][50]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_50_sort_keys = {
    for group_key, group in local.range_50_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 50 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_50_sorted = {
    for group_key, group in local.range_50_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 50 ? null : merge(group, {
      rules = [
        for sort_key in local.range_50_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_50_next_contiguous = {
    for group_key, group in local.range_50_sorted :
    group_key => length(local.range_keys[group_key]) <= 50 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][50]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][50]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][50]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][50]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][50]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][50]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][50] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_50_contiguous_forward_count = {
    for group_key, group in local.range_50_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 50 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_50_contiguous_base2 = {
    for group_key, group in local.range_50_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 50 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][50]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][50]].to_inclusive - rule.ranges[local.range_keys[group_key][50]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][50]].to_inclusive - rule.ranges[local.range_keys[group_key][50]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][50]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][50]].to_inclusive - rule.ranges[local.range_keys[group_key][50]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_50_squashed = {
    for group_key, group in local.range_50_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 50 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][50] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_51_with_sort_keys = {
    for group_key, group in local.range_50_squashed :
    group_key => length(local.range_keys[group_key]) <= 51 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][51]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][51]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][51]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][51]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][51]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][51]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][51]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][51]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][51]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][51]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_51_sort_keys = {
    for group_key, group in local.range_51_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 51 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_51_sorted = {
    for group_key, group in local.range_51_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 51 ? null : merge(group, {
      rules = [
        for sort_key in local.range_51_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_51_next_contiguous = {
    for group_key, group in local.range_51_sorted :
    group_key => length(local.range_keys[group_key]) <= 51 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][51]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][51]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][51]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][51]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][51]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][51]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][51] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_51_contiguous_forward_count = {
    for group_key, group in local.range_51_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 51 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_51_contiguous_base2 = {
    for group_key, group in local.range_51_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 51 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][51]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][51]].to_inclusive - rule.ranges[local.range_keys[group_key][51]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][51]].to_inclusive - rule.ranges[local.range_keys[group_key][51]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][51]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][51]].to_inclusive - rule.ranges[local.range_keys[group_key][51]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_51_squashed = {
    for group_key, group in local.range_51_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 51 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][51] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_52_with_sort_keys = {
    for group_key, group in local.range_51_squashed :
    group_key => length(local.range_keys[group_key]) <= 52 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][52]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][52]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][52]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][52]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][52]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][52]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][52]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][52]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][52]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][52]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_52_sort_keys = {
    for group_key, group in local.range_52_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 52 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_52_sorted = {
    for group_key, group in local.range_52_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 52 ? null : merge(group, {
      rules = [
        for sort_key in local.range_52_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_52_next_contiguous = {
    for group_key, group in local.range_52_sorted :
    group_key => length(local.range_keys[group_key]) <= 52 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][52]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][52]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][52]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][52]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][52]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][52]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][52] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_52_contiguous_forward_count = {
    for group_key, group in local.range_52_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 52 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_52_contiguous_base2 = {
    for group_key, group in local.range_52_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 52 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][52]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][52]].to_inclusive - rule.ranges[local.range_keys[group_key][52]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][52]].to_inclusive - rule.ranges[local.range_keys[group_key][52]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][52]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][52]].to_inclusive - rule.ranges[local.range_keys[group_key][52]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_52_squashed = {
    for group_key, group in local.range_52_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 52 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][52] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_53_with_sort_keys = {
    for group_key, group in local.range_52_squashed :
    group_key => length(local.range_keys[group_key]) <= 53 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][53]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][53]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][53]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][53]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][53]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][53]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][53]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][53]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][53]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][53]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_53_sort_keys = {
    for group_key, group in local.range_53_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 53 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_53_sorted = {
    for group_key, group in local.range_53_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 53 ? null : merge(group, {
      rules = [
        for sort_key in local.range_53_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_53_next_contiguous = {
    for group_key, group in local.range_53_sorted :
    group_key => length(local.range_keys[group_key]) <= 53 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][53]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][53]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][53]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][53]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][53]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][53]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][53] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_53_contiguous_forward_count = {
    for group_key, group in local.range_53_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 53 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_53_contiguous_base2 = {
    for group_key, group in local.range_53_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 53 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][53]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][53]].to_inclusive - rule.ranges[local.range_keys[group_key][53]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][53]].to_inclusive - rule.ranges[local.range_keys[group_key][53]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][53]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][53]].to_inclusive - rule.ranges[local.range_keys[group_key][53]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_53_squashed = {
    for group_key, group in local.range_53_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 53 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][53] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_54_with_sort_keys = {
    for group_key, group in local.range_53_squashed :
    group_key => length(local.range_keys[group_key]) <= 54 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][54]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][54]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][54]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][54]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][54]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][54]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][54]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][54]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][54]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][54]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_54_sort_keys = {
    for group_key, group in local.range_54_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 54 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_54_sorted = {
    for group_key, group in local.range_54_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 54 ? null : merge(group, {
      rules = [
        for sort_key in local.range_54_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_54_next_contiguous = {
    for group_key, group in local.range_54_sorted :
    group_key => length(local.range_keys[group_key]) <= 54 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][54]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][54]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][54]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][54]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][54]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][54]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][54] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_54_contiguous_forward_count = {
    for group_key, group in local.range_54_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 54 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_54_contiguous_base2 = {
    for group_key, group in local.range_54_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 54 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][54]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][54]].to_inclusive - rule.ranges[local.range_keys[group_key][54]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][54]].to_inclusive - rule.ranges[local.range_keys[group_key][54]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][54]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][54]].to_inclusive - rule.ranges[local.range_keys[group_key][54]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_54_squashed = {
    for group_key, group in local.range_54_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 54 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][54] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_55_with_sort_keys = {
    for group_key, group in local.range_54_squashed :
    group_key => length(local.range_keys[group_key]) <= 55 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][55]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][55]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][55]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][55]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][55]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][55]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][55]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][55]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][55]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][55]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_55_sort_keys = {
    for group_key, group in local.range_55_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 55 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_55_sorted = {
    for group_key, group in local.range_55_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 55 ? null : merge(group, {
      rules = [
        for sort_key in local.range_55_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_55_next_contiguous = {
    for group_key, group in local.range_55_sorted :
    group_key => length(local.range_keys[group_key]) <= 55 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][55]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][55]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][55]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][55]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][55]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][55]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][55] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_55_contiguous_forward_count = {
    for group_key, group in local.range_55_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 55 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_55_contiguous_base2 = {
    for group_key, group in local.range_55_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 55 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][55]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][55]].to_inclusive - rule.ranges[local.range_keys[group_key][55]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][55]].to_inclusive - rule.ranges[local.range_keys[group_key][55]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][55]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][55]].to_inclusive - rule.ranges[local.range_keys[group_key][55]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_55_squashed = {
    for group_key, group in local.range_55_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 55 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][55] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_56_with_sort_keys = {
    for group_key, group in local.range_55_squashed :
    group_key => length(local.range_keys[group_key]) <= 56 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][56]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][56]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][56]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][56]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][56]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][56]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][56]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][56]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][56]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][56]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_56_sort_keys = {
    for group_key, group in local.range_56_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 56 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_56_sorted = {
    for group_key, group in local.range_56_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 56 ? null : merge(group, {
      rules = [
        for sort_key in local.range_56_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_56_next_contiguous = {
    for group_key, group in local.range_56_sorted :
    group_key => length(local.range_keys[group_key]) <= 56 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][56]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][56]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][56]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][56]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][56]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][56]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][56] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_56_contiguous_forward_count = {
    for group_key, group in local.range_56_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 56 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_56_contiguous_base2 = {
    for group_key, group in local.range_56_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 56 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][56]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][56]].to_inclusive - rule.ranges[local.range_keys[group_key][56]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][56]].to_inclusive - rule.ranges[local.range_keys[group_key][56]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][56]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][56]].to_inclusive - rule.ranges[local.range_keys[group_key][56]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_56_squashed = {
    for group_key, group in local.range_56_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 56 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][56] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_57_with_sort_keys = {
    for group_key, group in local.range_56_squashed :
    group_key => length(local.range_keys[group_key]) <= 57 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][57]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][57]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][57]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][57]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][57]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][57]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][57]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][57]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][57]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][57]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_57_sort_keys = {
    for group_key, group in local.range_57_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 57 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_57_sorted = {
    for group_key, group in local.range_57_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 57 ? null : merge(group, {
      rules = [
        for sort_key in local.range_57_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_57_next_contiguous = {
    for group_key, group in local.range_57_sorted :
    group_key => length(local.range_keys[group_key]) <= 57 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][57]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][57]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][57]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][57]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][57]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][57]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][57] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_57_contiguous_forward_count = {
    for group_key, group in local.range_57_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 57 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_57_contiguous_base2 = {
    for group_key, group in local.range_57_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 57 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][57]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][57]].to_inclusive - rule.ranges[local.range_keys[group_key][57]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][57]].to_inclusive - rule.ranges[local.range_keys[group_key][57]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][57]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][57]].to_inclusive - rule.ranges[local.range_keys[group_key][57]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_57_squashed = {
    for group_key, group in local.range_57_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 57 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][57] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_58_with_sort_keys = {
    for group_key, group in local.range_57_squashed :
    group_key => length(local.range_keys[group_key]) <= 58 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][58]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][58]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][58]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][58]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][58]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][58]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][58]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][58]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][58]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][58]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_58_sort_keys = {
    for group_key, group in local.range_58_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 58 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_58_sorted = {
    for group_key, group in local.range_58_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 58 ? null : merge(group, {
      rules = [
        for sort_key in local.range_58_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_58_next_contiguous = {
    for group_key, group in local.range_58_sorted :
    group_key => length(local.range_keys[group_key]) <= 58 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][58]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][58]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][58]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][58]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][58]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][58]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][58] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_58_contiguous_forward_count = {
    for group_key, group in local.range_58_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 58 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_58_contiguous_base2 = {
    for group_key, group in local.range_58_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 58 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][58]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][58]].to_inclusive - rule.ranges[local.range_keys[group_key][58]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][58]].to_inclusive - rule.ranges[local.range_keys[group_key][58]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][58]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][58]].to_inclusive - rule.ranges[local.range_keys[group_key][58]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_58_squashed = {
    for group_key, group in local.range_58_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 58 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][58] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_59_with_sort_keys = {
    for group_key, group in local.range_58_squashed :
    group_key => length(local.range_keys[group_key]) <= 59 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][59]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][59]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][59]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][59]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][59]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][59]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][59]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][59]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][59]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][59]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_59_sort_keys = {
    for group_key, group in local.range_59_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 59 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_59_sorted = {
    for group_key, group in local.range_59_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 59 ? null : merge(group, {
      rules = [
        for sort_key in local.range_59_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_59_next_contiguous = {
    for group_key, group in local.range_59_sorted :
    group_key => length(local.range_keys[group_key]) <= 59 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][59]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][59]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][59]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][59]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][59]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][59]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][59] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_59_contiguous_forward_count = {
    for group_key, group in local.range_59_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 59 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_59_contiguous_base2 = {
    for group_key, group in local.range_59_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 59 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][59]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][59]].to_inclusive - rule.ranges[local.range_keys[group_key][59]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][59]].to_inclusive - rule.ranges[local.range_keys[group_key][59]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][59]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][59]].to_inclusive - rule.ranges[local.range_keys[group_key][59]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_59_squashed = {
    for group_key, group in local.range_59_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 59 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][59] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_60_with_sort_keys = {
    for group_key, group in local.range_59_squashed :
    group_key => length(local.range_keys[group_key]) <= 60 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][60]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][60]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][60]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][60]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][60]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][60]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][60]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][60]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][60]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][60]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_60_sort_keys = {
    for group_key, group in local.range_60_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 60 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_60_sorted = {
    for group_key, group in local.range_60_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 60 ? null : merge(group, {
      rules = [
        for sort_key in local.range_60_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_60_next_contiguous = {
    for group_key, group in local.range_60_sorted :
    group_key => length(local.range_keys[group_key]) <= 60 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][60]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][60]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][60]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][60]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][60]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][60]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][60] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_60_contiguous_forward_count = {
    for group_key, group in local.range_60_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 60 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_60_contiguous_base2 = {
    for group_key, group in local.range_60_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 60 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][60]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][60]].to_inclusive - rule.ranges[local.range_keys[group_key][60]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][60]].to_inclusive - rule.ranges[local.range_keys[group_key][60]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][60]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][60]].to_inclusive - rule.ranges[local.range_keys[group_key][60]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_60_squashed = {
    for group_key, group in local.range_60_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 60 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][60] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_61_with_sort_keys = {
    for group_key, group in local.range_60_squashed :
    group_key => length(local.range_keys[group_key]) <= 61 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][61]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][61]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][61]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][61]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][61]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][61]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][61]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][61]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][61]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][61]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_61_sort_keys = {
    for group_key, group in local.range_61_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 61 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_61_sorted = {
    for group_key, group in local.range_61_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 61 ? null : merge(group, {
      rules = [
        for sort_key in local.range_61_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_61_next_contiguous = {
    for group_key, group in local.range_61_sorted :
    group_key => length(local.range_keys[group_key]) <= 61 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][61]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][61]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][61]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][61]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][61]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][61]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][61] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_61_contiguous_forward_count = {
    for group_key, group in local.range_61_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 61 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_61_contiguous_base2 = {
    for group_key, group in local.range_61_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 61 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][61]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][61]].to_inclusive - rule.ranges[local.range_keys[group_key][61]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][61]].to_inclusive - rule.ranges[local.range_keys[group_key][61]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][61]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][61]].to_inclusive - rule.ranges[local.range_keys[group_key][61]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_61_squashed = {
    for group_key, group in local.range_61_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 61 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][61] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_62_with_sort_keys = {
    for group_key, group in local.range_61_squashed :
    group_key => length(local.range_keys[group_key]) <= 62 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][62]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][62]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][62]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][62]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][62]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][62]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][62]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][62]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][62]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][62]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_62_sort_keys = {
    for group_key, group in local.range_62_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 62 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_62_sorted = {
    for group_key, group in local.range_62_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 62 ? null : merge(group, {
      rules = [
        for sort_key in local.range_62_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_62_next_contiguous = {
    for group_key, group in local.range_62_sorted :
    group_key => length(local.range_keys[group_key]) <= 62 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][62]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][62]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][62]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][62]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][62]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][62]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][62] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_62_contiguous_forward_count = {
    for group_key, group in local.range_62_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 62 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_62_contiguous_base2 = {
    for group_key, group in local.range_62_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 62 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][62]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][62]].to_inclusive - rule.ranges[local.range_keys[group_key][62]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][62]].to_inclusive - rule.ranges[local.range_keys[group_key][62]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][62]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][62]].to_inclusive - rule.ranges[local.range_keys[group_key][62]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_62_squashed = {
    for group_key, group in local.range_62_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 62 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][62] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_63_with_sort_keys = {
    for group_key, group in local.range_62_squashed :
    group_key => length(local.range_keys[group_key]) <= 63 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][63]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][63]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][63]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][63]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][63]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][63]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][63]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][63]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][63]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][63]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_63_sort_keys = {
    for group_key, group in local.range_63_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 63 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_63_sorted = {
    for group_key, group in local.range_63_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 63 ? null : merge(group, {
      rules = [
        for sort_key in local.range_63_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_63_next_contiguous = {
    for group_key, group in local.range_63_sorted :
    group_key => length(local.range_keys[group_key]) <= 63 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][63]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][63]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][63]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][63]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][63]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][63]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][63] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_63_contiguous_forward_count = {
    for group_key, group in local.range_63_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 63 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_63_contiguous_base2 = {
    for group_key, group in local.range_63_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 63 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][63]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][63]].to_inclusive - rule.ranges[local.range_keys[group_key][63]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][63]].to_inclusive - rule.ranges[local.range_keys[group_key][63]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][63]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][63]].to_inclusive - rule.ranges[local.range_keys[group_key][63]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_63_squashed = {
    for group_key, group in local.range_63_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 63 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][63] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_64_with_sort_keys = {
    for group_key, group in local.range_63_squashed :
    group_key => length(local.range_keys[group_key]) <= 64 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][64]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][64]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][64]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][64]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][64]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][64]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][64]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][64]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][64]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][64]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_64_sort_keys = {
    for group_key, group in local.range_64_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 64 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_64_sorted = {
    for group_key, group in local.range_64_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 64 ? null : merge(group, {
      rules = [
        for sort_key in local.range_64_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_64_next_contiguous = {
    for group_key, group in local.range_64_sorted :
    group_key => length(local.range_keys[group_key]) <= 64 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][64]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][64]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][64]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][64]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][64]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][64]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][64] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_64_contiguous_forward_count = {
    for group_key, group in local.range_64_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 64 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_64_contiguous_base2 = {
    for group_key, group in local.range_64_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 64 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][64]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][64]].to_inclusive - rule.ranges[local.range_keys[group_key][64]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][64]].to_inclusive - rule.ranges[local.range_keys[group_key][64]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][64]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][64]].to_inclusive - rule.ranges[local.range_keys[group_key][64]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_64_squashed = {
    for group_key, group in local.range_64_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 64 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][64] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_65_with_sort_keys = {
    for group_key, group in local.range_64_squashed :
    group_key => length(local.range_keys[group_key]) <= 65 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][65]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][65]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][65]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][65]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][65]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][65]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][65]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][65]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][65]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][65]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_65_sort_keys = {
    for group_key, group in local.range_65_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 65 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_65_sorted = {
    for group_key, group in local.range_65_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 65 ? null : merge(group, {
      rules = [
        for sort_key in local.range_65_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_65_next_contiguous = {
    for group_key, group in local.range_65_sorted :
    group_key => length(local.range_keys[group_key]) <= 65 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][65]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][65]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][65]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][65]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][65]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][65]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][65] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_65_contiguous_forward_count = {
    for group_key, group in local.range_65_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 65 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_65_contiguous_base2 = {
    for group_key, group in local.range_65_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 65 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][65]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][65]].to_inclusive - rule.ranges[local.range_keys[group_key][65]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][65]].to_inclusive - rule.ranges[local.range_keys[group_key][65]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][65]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][65]].to_inclusive - rule.ranges[local.range_keys[group_key][65]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_65_squashed = {
    for group_key, group in local.range_65_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 65 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][65] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_66_with_sort_keys = {
    for group_key, group in local.range_65_squashed :
    group_key => length(local.range_keys[group_key]) <= 66 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][66]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][66]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][66]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][66]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][66]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][66]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][66]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][66]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][66]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][66]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_66_sort_keys = {
    for group_key, group in local.range_66_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 66 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_66_sorted = {
    for group_key, group in local.range_66_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 66 ? null : merge(group, {
      rules = [
        for sort_key in local.range_66_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_66_next_contiguous = {
    for group_key, group in local.range_66_sorted :
    group_key => length(local.range_keys[group_key]) <= 66 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][66]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][66]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][66]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][66]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][66]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][66]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][66] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_66_contiguous_forward_count = {
    for group_key, group in local.range_66_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 66 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_66_contiguous_base2 = {
    for group_key, group in local.range_66_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 66 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][66]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][66]].to_inclusive - rule.ranges[local.range_keys[group_key][66]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][66]].to_inclusive - rule.ranges[local.range_keys[group_key][66]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][66]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][66]].to_inclusive - rule.ranges[local.range_keys[group_key][66]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_66_squashed = {
    for group_key, group in local.range_66_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 66 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][66] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_67_with_sort_keys = {
    for group_key, group in local.range_66_squashed :
    group_key => length(local.range_keys[group_key]) <= 67 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][67]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][67]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][67]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][67]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][67]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][67]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][67]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][67]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][67]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][67]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_67_sort_keys = {
    for group_key, group in local.range_67_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 67 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_67_sorted = {
    for group_key, group in local.range_67_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 67 ? null : merge(group, {
      rules = [
        for sort_key in local.range_67_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_67_next_contiguous = {
    for group_key, group in local.range_67_sorted :
    group_key => length(local.range_keys[group_key]) <= 67 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][67]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][67]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][67]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][67]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][67]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][67]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][67] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_67_contiguous_forward_count = {
    for group_key, group in local.range_67_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 67 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_67_contiguous_base2 = {
    for group_key, group in local.range_67_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 67 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][67]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][67]].to_inclusive - rule.ranges[local.range_keys[group_key][67]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][67]].to_inclusive - rule.ranges[local.range_keys[group_key][67]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][67]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][67]].to_inclusive - rule.ranges[local.range_keys[group_key][67]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_67_squashed = {
    for group_key, group in local.range_67_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 67 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][67] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_68_with_sort_keys = {
    for group_key, group in local.range_67_squashed :
    group_key => length(local.range_keys[group_key]) <= 68 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][68]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][68]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][68]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][68]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][68]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][68]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][68]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][68]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][68]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][68]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_68_sort_keys = {
    for group_key, group in local.range_68_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 68 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_68_sorted = {
    for group_key, group in local.range_68_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 68 ? null : merge(group, {
      rules = [
        for sort_key in local.range_68_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_68_next_contiguous = {
    for group_key, group in local.range_68_sorted :
    group_key => length(local.range_keys[group_key]) <= 68 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][68]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][68]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][68]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][68]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][68]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][68]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][68] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_68_contiguous_forward_count = {
    for group_key, group in local.range_68_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 68 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_68_contiguous_base2 = {
    for group_key, group in local.range_68_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 68 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][68]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][68]].to_inclusive - rule.ranges[local.range_keys[group_key][68]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][68]].to_inclusive - rule.ranges[local.range_keys[group_key][68]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][68]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][68]].to_inclusive - rule.ranges[local.range_keys[group_key][68]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_68_squashed = {
    for group_key, group in local.range_68_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 68 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][68] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_69_with_sort_keys = {
    for group_key, group in local.range_68_squashed :
    group_key => length(local.range_keys[group_key]) <= 69 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][69]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][69]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][69]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][69]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][69]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][69]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][69]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][69]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][69]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][69]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_69_sort_keys = {
    for group_key, group in local.range_69_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 69 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_69_sorted = {
    for group_key, group in local.range_69_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 69 ? null : merge(group, {
      rules = [
        for sort_key in local.range_69_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_69_next_contiguous = {
    for group_key, group in local.range_69_sorted :
    group_key => length(local.range_keys[group_key]) <= 69 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][69]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][69]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][69]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][69]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][69]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][69]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][69] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_69_contiguous_forward_count = {
    for group_key, group in local.range_69_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 69 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_69_contiguous_base2 = {
    for group_key, group in local.range_69_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 69 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][69]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][69]].to_inclusive - rule.ranges[local.range_keys[group_key][69]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][69]].to_inclusive - rule.ranges[local.range_keys[group_key][69]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][69]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][69]].to_inclusive - rule.ranges[local.range_keys[group_key][69]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_69_squashed = {
    for group_key, group in local.range_69_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 69 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][69] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_70_with_sort_keys = {
    for group_key, group in local.range_69_squashed :
    group_key => length(local.range_keys[group_key]) <= 70 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][70]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][70]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][70]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][70]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][70]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][70]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][70]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][70]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][70]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][70]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_70_sort_keys = {
    for group_key, group in local.range_70_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 70 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_70_sorted = {
    for group_key, group in local.range_70_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 70 ? null : merge(group, {
      rules = [
        for sort_key in local.range_70_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_70_next_contiguous = {
    for group_key, group in local.range_70_sorted :
    group_key => length(local.range_keys[group_key]) <= 70 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][70]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][70]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][70]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][70]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][70]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][70]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][70] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_70_contiguous_forward_count = {
    for group_key, group in local.range_70_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 70 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_70_contiguous_base2 = {
    for group_key, group in local.range_70_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 70 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][70]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][70]].to_inclusive - rule.ranges[local.range_keys[group_key][70]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][70]].to_inclusive - rule.ranges[local.range_keys[group_key][70]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][70]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][70]].to_inclusive - rule.ranges[local.range_keys[group_key][70]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_70_squashed = {
    for group_key, group in local.range_70_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 70 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][70] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_71_with_sort_keys = {
    for group_key, group in local.range_70_squashed :
    group_key => length(local.range_keys[group_key]) <= 71 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][71]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][71]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][71]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][71]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][71]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][71]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][71]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][71]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][71]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][71]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_71_sort_keys = {
    for group_key, group in local.range_71_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 71 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_71_sorted = {
    for group_key, group in local.range_71_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 71 ? null : merge(group, {
      rules = [
        for sort_key in local.range_71_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_71_next_contiguous = {
    for group_key, group in local.range_71_sorted :
    group_key => length(local.range_keys[group_key]) <= 71 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][71]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][71]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][71]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][71]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][71]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][71]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][71] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_71_contiguous_forward_count = {
    for group_key, group in local.range_71_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 71 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_71_contiguous_base2 = {
    for group_key, group in local.range_71_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 71 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][71]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][71]].to_inclusive - rule.ranges[local.range_keys[group_key][71]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][71]].to_inclusive - rule.ranges[local.range_keys[group_key][71]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][71]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][71]].to_inclusive - rule.ranges[local.range_keys[group_key][71]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_71_squashed = {
    for group_key, group in local.range_71_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 71 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][71] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_72_with_sort_keys = {
    for group_key, group in local.range_71_squashed :
    group_key => length(local.range_keys[group_key]) <= 72 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][72]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][72]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][72]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][72]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][72]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][72]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][72]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][72]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][72]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][72]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_72_sort_keys = {
    for group_key, group in local.range_72_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 72 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_72_sorted = {
    for group_key, group in local.range_72_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 72 ? null : merge(group, {
      rules = [
        for sort_key in local.range_72_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_72_next_contiguous = {
    for group_key, group in local.range_72_sorted :
    group_key => length(local.range_keys[group_key]) <= 72 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][72]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][72]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][72]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][72]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][72]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][72]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][72] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_72_contiguous_forward_count = {
    for group_key, group in local.range_72_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 72 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_72_contiguous_base2 = {
    for group_key, group in local.range_72_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 72 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][72]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][72]].to_inclusive - rule.ranges[local.range_keys[group_key][72]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][72]].to_inclusive - rule.ranges[local.range_keys[group_key][72]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][72]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][72]].to_inclusive - rule.ranges[local.range_keys[group_key][72]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_72_squashed = {
    for group_key, group in local.range_72_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 72 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][72] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_73_with_sort_keys = {
    for group_key, group in local.range_72_squashed :
    group_key => length(local.range_keys[group_key]) <= 73 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][73]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][73]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][73]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][73]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][73]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][73]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][73]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][73]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][73]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][73]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_73_sort_keys = {
    for group_key, group in local.range_73_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 73 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_73_sorted = {
    for group_key, group in local.range_73_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 73 ? null : merge(group, {
      rules = [
        for sort_key in local.range_73_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_73_next_contiguous = {
    for group_key, group in local.range_73_sorted :
    group_key => length(local.range_keys[group_key]) <= 73 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][73]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][73]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][73]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][73]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][73]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][73]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][73] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_73_contiguous_forward_count = {
    for group_key, group in local.range_73_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 73 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_73_contiguous_base2 = {
    for group_key, group in local.range_73_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 73 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][73]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][73]].to_inclusive - rule.ranges[local.range_keys[group_key][73]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][73]].to_inclusive - rule.ranges[local.range_keys[group_key][73]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][73]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][73]].to_inclusive - rule.ranges[local.range_keys[group_key][73]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_73_squashed = {
    for group_key, group in local.range_73_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 73 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][73] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_74_with_sort_keys = {
    for group_key, group in local.range_73_squashed :
    group_key => length(local.range_keys[group_key]) <= 74 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][74]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][74]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][74]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][74]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][74]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][74]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][74]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][74]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][74]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][74]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_74_sort_keys = {
    for group_key, group in local.range_74_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 74 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_74_sorted = {
    for group_key, group in local.range_74_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 74 ? null : merge(group, {
      rules = [
        for sort_key in local.range_74_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_74_next_contiguous = {
    for group_key, group in local.range_74_sorted :
    group_key => length(local.range_keys[group_key]) <= 74 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][74]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][74]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][74]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][74]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][74]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][74]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][74] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_74_contiguous_forward_count = {
    for group_key, group in local.range_74_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 74 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_74_contiguous_base2 = {
    for group_key, group in local.range_74_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 74 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][74]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][74]].to_inclusive - rule.ranges[local.range_keys[group_key][74]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][74]].to_inclusive - rule.ranges[local.range_keys[group_key][74]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][74]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][74]].to_inclusive - rule.ranges[local.range_keys[group_key][74]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_74_squashed = {
    for group_key, group in local.range_74_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 74 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][74] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_75_with_sort_keys = {
    for group_key, group in local.range_74_squashed :
    group_key => length(local.range_keys[group_key]) <= 75 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][75]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][75]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][75]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][75]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][75]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][75]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][75]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][75]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][75]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][75]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_75_sort_keys = {
    for group_key, group in local.range_75_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 75 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_75_sorted = {
    for group_key, group in local.range_75_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 75 ? null : merge(group, {
      rules = [
        for sort_key in local.range_75_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_75_next_contiguous = {
    for group_key, group in local.range_75_sorted :
    group_key => length(local.range_keys[group_key]) <= 75 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][75]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][75]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][75]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][75]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][75]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][75]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][75] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_75_contiguous_forward_count = {
    for group_key, group in local.range_75_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 75 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_75_contiguous_base2 = {
    for group_key, group in local.range_75_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 75 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][75]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][75]].to_inclusive - rule.ranges[local.range_keys[group_key][75]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][75]].to_inclusive - rule.ranges[local.range_keys[group_key][75]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][75]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][75]].to_inclusive - rule.ranges[local.range_keys[group_key][75]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_75_squashed = {
    for group_key, group in local.range_75_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 75 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][75] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_76_with_sort_keys = {
    for group_key, group in local.range_75_squashed :
    group_key => length(local.range_keys[group_key]) <= 76 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][76]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][76]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][76]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][76]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][76]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][76]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][76]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][76]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][76]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][76]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_76_sort_keys = {
    for group_key, group in local.range_76_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 76 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_76_sorted = {
    for group_key, group in local.range_76_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 76 ? null : merge(group, {
      rules = [
        for sort_key in local.range_76_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_76_next_contiguous = {
    for group_key, group in local.range_76_sorted :
    group_key => length(local.range_keys[group_key]) <= 76 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][76]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][76]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][76]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][76]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][76]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][76]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][76] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_76_contiguous_forward_count = {
    for group_key, group in local.range_76_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 76 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_76_contiguous_base2 = {
    for group_key, group in local.range_76_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 76 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][76]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][76]].to_inclusive - rule.ranges[local.range_keys[group_key][76]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][76]].to_inclusive - rule.ranges[local.range_keys[group_key][76]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][76]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][76]].to_inclusive - rule.ranges[local.range_keys[group_key][76]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_76_squashed = {
    for group_key, group in local.range_76_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 76 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][76] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_77_with_sort_keys = {
    for group_key, group in local.range_76_squashed :
    group_key => length(local.range_keys[group_key]) <= 77 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][77]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][77]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][77]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][77]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][77]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][77]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][77]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][77]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][77]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][77]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_77_sort_keys = {
    for group_key, group in local.range_77_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 77 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_77_sorted = {
    for group_key, group in local.range_77_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 77 ? null : merge(group, {
      rules = [
        for sort_key in local.range_77_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_77_next_contiguous = {
    for group_key, group in local.range_77_sorted :
    group_key => length(local.range_keys[group_key]) <= 77 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][77]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][77]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][77]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][77]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][77]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][77]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][77] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_77_contiguous_forward_count = {
    for group_key, group in local.range_77_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 77 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_77_contiguous_base2 = {
    for group_key, group in local.range_77_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 77 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][77]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][77]].to_inclusive - rule.ranges[local.range_keys[group_key][77]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][77]].to_inclusive - rule.ranges[local.range_keys[group_key][77]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][77]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][77]].to_inclusive - rule.ranges[local.range_keys[group_key][77]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_77_squashed = {
    for group_key, group in local.range_77_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 77 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][77] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_78_with_sort_keys = {
    for group_key, group in local.range_77_squashed :
    group_key => length(local.range_keys[group_key]) <= 78 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][78]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][78]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][78]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][78]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][78]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][78]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][78]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][78]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][78]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][78]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_78_sort_keys = {
    for group_key, group in local.range_78_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 78 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_78_sorted = {
    for group_key, group in local.range_78_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 78 ? null : merge(group, {
      rules = [
        for sort_key in local.range_78_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_78_next_contiguous = {
    for group_key, group in local.range_78_sorted :
    group_key => length(local.range_keys[group_key]) <= 78 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][78]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][78]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][78]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][78]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][78]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][78]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][78] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_78_contiguous_forward_count = {
    for group_key, group in local.range_78_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 78 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_78_contiguous_base2 = {
    for group_key, group in local.range_78_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 78 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][78]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][78]].to_inclusive - rule.ranges[local.range_keys[group_key][78]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][78]].to_inclusive - rule.ranges[local.range_keys[group_key][78]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][78]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][78]].to_inclusive - rule.ranges[local.range_keys[group_key][78]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_78_squashed = {
    for group_key, group in local.range_78_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 78 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][78] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_79_with_sort_keys = {
    for group_key, group in local.range_78_squashed :
    group_key => length(local.range_keys[group_key]) <= 79 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][79]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][79]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][79]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][79]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][79]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][79]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][79]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][79]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][79]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][79]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_79_sort_keys = {
    for group_key, group in local.range_79_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 79 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_79_sorted = {
    for group_key, group in local.range_79_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 79 ? null : merge(group, {
      rules = [
        for sort_key in local.range_79_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_79_next_contiguous = {
    for group_key, group in local.range_79_sorted :
    group_key => length(local.range_keys[group_key]) <= 79 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][79]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][79]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][79]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][79]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][79]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][79]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][79] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_79_contiguous_forward_count = {
    for group_key, group in local.range_79_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 79 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_79_contiguous_base2 = {
    for group_key, group in local.range_79_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 79 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][79]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][79]].to_inclusive - rule.ranges[local.range_keys[group_key][79]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][79]].to_inclusive - rule.ranges[local.range_keys[group_key][79]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][79]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][79]].to_inclusive - rule.ranges[local.range_keys[group_key][79]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_79_squashed = {
    for group_key, group in local.range_79_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 79 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][79] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_80_with_sort_keys = {
    for group_key, group in local.range_79_squashed :
    group_key => length(local.range_keys[group_key]) <= 80 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][80]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][80]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][80]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][80]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][80]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][80]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][80]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][80]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][80]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][80]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_80_sort_keys = {
    for group_key, group in local.range_80_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 80 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_80_sorted = {
    for group_key, group in local.range_80_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 80 ? null : merge(group, {
      rules = [
        for sort_key in local.range_80_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_80_next_contiguous = {
    for group_key, group in local.range_80_sorted :
    group_key => length(local.range_keys[group_key]) <= 80 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][80]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][80]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][80]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][80]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][80]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][80]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][80] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_80_contiguous_forward_count = {
    for group_key, group in local.range_80_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 80 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_80_contiguous_base2 = {
    for group_key, group in local.range_80_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 80 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][80]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][80]].to_inclusive - rule.ranges[local.range_keys[group_key][80]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][80]].to_inclusive - rule.ranges[local.range_keys[group_key][80]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][80]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][80]].to_inclusive - rule.ranges[local.range_keys[group_key][80]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_80_squashed = {
    for group_key, group in local.range_80_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 80 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][80] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_81_with_sort_keys = {
    for group_key, group in local.range_80_squashed :
    group_key => length(local.range_keys[group_key]) <= 81 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][81]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][81]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][81]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][81]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][81]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][81]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][81]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][81]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][81]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][81]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_81_sort_keys = {
    for group_key, group in local.range_81_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 81 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_81_sorted = {
    for group_key, group in local.range_81_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 81 ? null : merge(group, {
      rules = [
        for sort_key in local.range_81_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_81_next_contiguous = {
    for group_key, group in local.range_81_sorted :
    group_key => length(local.range_keys[group_key]) <= 81 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][81]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][81]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][81]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][81]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][81]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][81]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][81] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_81_contiguous_forward_count = {
    for group_key, group in local.range_81_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 81 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_81_contiguous_base2 = {
    for group_key, group in local.range_81_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 81 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][81]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][81]].to_inclusive - rule.ranges[local.range_keys[group_key][81]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][81]].to_inclusive - rule.ranges[local.range_keys[group_key][81]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][81]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][81]].to_inclusive - rule.ranges[local.range_keys[group_key][81]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_81_squashed = {
    for group_key, group in local.range_81_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 81 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][81] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_82_with_sort_keys = {
    for group_key, group in local.range_81_squashed :
    group_key => length(local.range_keys[group_key]) <= 82 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][82]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][82]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][82]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][82]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][82]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][82]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][82]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][82]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][82]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][82]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_82_sort_keys = {
    for group_key, group in local.range_82_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 82 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_82_sorted = {
    for group_key, group in local.range_82_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 82 ? null : merge(group, {
      rules = [
        for sort_key in local.range_82_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_82_next_contiguous = {
    for group_key, group in local.range_82_sorted :
    group_key => length(local.range_keys[group_key]) <= 82 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][82]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][82]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][82]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][82]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][82]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][82]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][82] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_82_contiguous_forward_count = {
    for group_key, group in local.range_82_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 82 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_82_contiguous_base2 = {
    for group_key, group in local.range_82_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 82 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][82]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][82]].to_inclusive - rule.ranges[local.range_keys[group_key][82]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][82]].to_inclusive - rule.ranges[local.range_keys[group_key][82]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][82]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][82]].to_inclusive - rule.ranges[local.range_keys[group_key][82]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_82_squashed = {
    for group_key, group in local.range_82_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 82 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][82] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_83_with_sort_keys = {
    for group_key, group in local.range_82_squashed :
    group_key => length(local.range_keys[group_key]) <= 83 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][83]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][83]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][83]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][83]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][83]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][83]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][83]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][83]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][83]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][83]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_83_sort_keys = {
    for group_key, group in local.range_83_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 83 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_83_sorted = {
    for group_key, group in local.range_83_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 83 ? null : merge(group, {
      rules = [
        for sort_key in local.range_83_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_83_next_contiguous = {
    for group_key, group in local.range_83_sorted :
    group_key => length(local.range_keys[group_key]) <= 83 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][83]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][83]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][83]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][83]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][83]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][83]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][83] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_83_contiguous_forward_count = {
    for group_key, group in local.range_83_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 83 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_83_contiguous_base2 = {
    for group_key, group in local.range_83_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 83 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][83]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][83]].to_inclusive - rule.ranges[local.range_keys[group_key][83]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][83]].to_inclusive - rule.ranges[local.range_keys[group_key][83]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][83]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][83]].to_inclusive - rule.ranges[local.range_keys[group_key][83]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_83_squashed = {
    for group_key, group in local.range_83_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 83 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][83] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_84_with_sort_keys = {
    for group_key, group in local.range_83_squashed :
    group_key => length(local.range_keys[group_key]) <= 84 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][84]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][84]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][84]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][84]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][84]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][84]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][84]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][84]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][84]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][84]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_84_sort_keys = {
    for group_key, group in local.range_84_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 84 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_84_sorted = {
    for group_key, group in local.range_84_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 84 ? null : merge(group, {
      rules = [
        for sort_key in local.range_84_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_84_next_contiguous = {
    for group_key, group in local.range_84_sorted :
    group_key => length(local.range_keys[group_key]) <= 84 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][84]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][84]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][84]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][84]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][84]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][84]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][84] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_84_contiguous_forward_count = {
    for group_key, group in local.range_84_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 84 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_84_contiguous_base2 = {
    for group_key, group in local.range_84_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 84 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][84]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][84]].to_inclusive - rule.ranges[local.range_keys[group_key][84]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][84]].to_inclusive - rule.ranges[local.range_keys[group_key][84]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][84]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][84]].to_inclusive - rule.ranges[local.range_keys[group_key][84]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_84_squashed = {
    for group_key, group in local.range_84_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 84 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][84] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_85_with_sort_keys = {
    for group_key, group in local.range_84_squashed :
    group_key => length(local.range_keys[group_key]) <= 85 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][85]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][85]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][85]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][85]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][85]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][85]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][85]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][85]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][85]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][85]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_85_sort_keys = {
    for group_key, group in local.range_85_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 85 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_85_sorted = {
    for group_key, group in local.range_85_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 85 ? null : merge(group, {
      rules = [
        for sort_key in local.range_85_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_85_next_contiguous = {
    for group_key, group in local.range_85_sorted :
    group_key => length(local.range_keys[group_key]) <= 85 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][85]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][85]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][85]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][85]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][85]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][85]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][85] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_85_contiguous_forward_count = {
    for group_key, group in local.range_85_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 85 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_85_contiguous_base2 = {
    for group_key, group in local.range_85_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 85 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][85]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][85]].to_inclusive - rule.ranges[local.range_keys[group_key][85]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][85]].to_inclusive - rule.ranges[local.range_keys[group_key][85]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][85]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][85]].to_inclusive - rule.ranges[local.range_keys[group_key][85]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_85_squashed = {
    for group_key, group in local.range_85_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 85 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][85] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_86_with_sort_keys = {
    for group_key, group in local.range_85_squashed :
    group_key => length(local.range_keys[group_key]) <= 86 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][86]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][86]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][86]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][86]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][86]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][86]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][86]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][86]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][86]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][86]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_86_sort_keys = {
    for group_key, group in local.range_86_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 86 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_86_sorted = {
    for group_key, group in local.range_86_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 86 ? null : merge(group, {
      rules = [
        for sort_key in local.range_86_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_86_next_contiguous = {
    for group_key, group in local.range_86_sorted :
    group_key => length(local.range_keys[group_key]) <= 86 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][86]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][86]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][86]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][86]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][86]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][86]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][86] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_86_contiguous_forward_count = {
    for group_key, group in local.range_86_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 86 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_86_contiguous_base2 = {
    for group_key, group in local.range_86_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 86 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][86]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][86]].to_inclusive - rule.ranges[local.range_keys[group_key][86]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][86]].to_inclusive - rule.ranges[local.range_keys[group_key][86]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][86]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][86]].to_inclusive - rule.ranges[local.range_keys[group_key][86]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_86_squashed = {
    for group_key, group in local.range_86_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 86 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][86] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_87_with_sort_keys = {
    for group_key, group in local.range_86_squashed :
    group_key => length(local.range_keys[group_key]) <= 87 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][87]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][87]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][87]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][87]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][87]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][87]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][87]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][87]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][87]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][87]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_87_sort_keys = {
    for group_key, group in local.range_87_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 87 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_87_sorted = {
    for group_key, group in local.range_87_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 87 ? null : merge(group, {
      rules = [
        for sort_key in local.range_87_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_87_next_contiguous = {
    for group_key, group in local.range_87_sorted :
    group_key => length(local.range_keys[group_key]) <= 87 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][87]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][87]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][87]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][87]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][87]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][87]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][87] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_87_contiguous_forward_count = {
    for group_key, group in local.range_87_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 87 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_87_contiguous_base2 = {
    for group_key, group in local.range_87_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 87 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][87]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][87]].to_inclusive - rule.ranges[local.range_keys[group_key][87]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][87]].to_inclusive - rule.ranges[local.range_keys[group_key][87]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][87]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][87]].to_inclusive - rule.ranges[local.range_keys[group_key][87]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_87_squashed = {
    for group_key, group in local.range_87_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 87 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][87] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_88_with_sort_keys = {
    for group_key, group in local.range_87_squashed :
    group_key => length(local.range_keys[group_key]) <= 88 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][88]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][88]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][88]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][88]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][88]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][88]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][88]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][88]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][88]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][88]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_88_sort_keys = {
    for group_key, group in local.range_88_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 88 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_88_sorted = {
    for group_key, group in local.range_88_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 88 ? null : merge(group, {
      rules = [
        for sort_key in local.range_88_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_88_next_contiguous = {
    for group_key, group in local.range_88_sorted :
    group_key => length(local.range_keys[group_key]) <= 88 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][88]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][88]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][88]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][88]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][88]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][88]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][88] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_88_contiguous_forward_count = {
    for group_key, group in local.range_88_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 88 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_88_contiguous_base2 = {
    for group_key, group in local.range_88_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 88 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][88]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][88]].to_inclusive - rule.ranges[local.range_keys[group_key][88]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][88]].to_inclusive - rule.ranges[local.range_keys[group_key][88]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][88]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][88]].to_inclusive - rule.ranges[local.range_keys[group_key][88]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_88_squashed = {
    for group_key, group in local.range_88_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 88 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][88] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_89_with_sort_keys = {
    for group_key, group in local.range_88_squashed :
    group_key => length(local.range_keys[group_key]) <= 89 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][89]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][89]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][89]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][89]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][89]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][89]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][89]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][89]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][89]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][89]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_89_sort_keys = {
    for group_key, group in local.range_89_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 89 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_89_sorted = {
    for group_key, group in local.range_89_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 89 ? null : merge(group, {
      rules = [
        for sort_key in local.range_89_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_89_next_contiguous = {
    for group_key, group in local.range_89_sorted :
    group_key => length(local.range_keys[group_key]) <= 89 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][89]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][89]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][89]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][89]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][89]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][89]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][89] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_89_contiguous_forward_count = {
    for group_key, group in local.range_89_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 89 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_89_contiguous_base2 = {
    for group_key, group in local.range_89_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 89 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][89]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][89]].to_inclusive - rule.ranges[local.range_keys[group_key][89]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][89]].to_inclusive - rule.ranges[local.range_keys[group_key][89]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][89]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][89]].to_inclusive - rule.ranges[local.range_keys[group_key][89]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_89_squashed = {
    for group_key, group in local.range_89_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 89 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][89] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_90_with_sort_keys = {
    for group_key, group in local.range_89_squashed :
    group_key => length(local.range_keys[group_key]) <= 90 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][90]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][90]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][90]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][90]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][90]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][90]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][90]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][90]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][90]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][90]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_90_sort_keys = {
    for group_key, group in local.range_90_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 90 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_90_sorted = {
    for group_key, group in local.range_90_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 90 ? null : merge(group, {
      rules = [
        for sort_key in local.range_90_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_90_next_contiguous = {
    for group_key, group in local.range_90_sorted :
    group_key => length(local.range_keys[group_key]) <= 90 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][90]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][90]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][90]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][90]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][90]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][90]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][90] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_90_contiguous_forward_count = {
    for group_key, group in local.range_90_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 90 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_90_contiguous_base2 = {
    for group_key, group in local.range_90_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 90 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][90]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][90]].to_inclusive - rule.ranges[local.range_keys[group_key][90]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][90]].to_inclusive - rule.ranges[local.range_keys[group_key][90]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][90]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][90]].to_inclusive - rule.ranges[local.range_keys[group_key][90]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_90_squashed = {
    for group_key, group in local.range_90_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 90 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][90] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_91_with_sort_keys = {
    for group_key, group in local.range_90_squashed :
    group_key => length(local.range_keys[group_key]) <= 91 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][91]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][91]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][91]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][91]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][91]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][91]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][91]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][91]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][91]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][91]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_91_sort_keys = {
    for group_key, group in local.range_91_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 91 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_91_sorted = {
    for group_key, group in local.range_91_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 91 ? null : merge(group, {
      rules = [
        for sort_key in local.range_91_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_91_next_contiguous = {
    for group_key, group in local.range_91_sorted :
    group_key => length(local.range_keys[group_key]) <= 91 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][91]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][91]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][91]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][91]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][91]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][91]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][91] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_91_contiguous_forward_count = {
    for group_key, group in local.range_91_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 91 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_91_contiguous_base2 = {
    for group_key, group in local.range_91_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 91 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][91]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][91]].to_inclusive - rule.ranges[local.range_keys[group_key][91]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][91]].to_inclusive - rule.ranges[local.range_keys[group_key][91]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][91]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][91]].to_inclusive - rule.ranges[local.range_keys[group_key][91]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_91_squashed = {
    for group_key, group in local.range_91_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 91 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][91] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_92_with_sort_keys = {
    for group_key, group in local.range_91_squashed :
    group_key => length(local.range_keys[group_key]) <= 92 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][92]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][92]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][92]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][92]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][92]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][92]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][92]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][92]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][92]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][92]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_92_sort_keys = {
    for group_key, group in local.range_92_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 92 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_92_sorted = {
    for group_key, group in local.range_92_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 92 ? null : merge(group, {
      rules = [
        for sort_key in local.range_92_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_92_next_contiguous = {
    for group_key, group in local.range_92_sorted :
    group_key => length(local.range_keys[group_key]) <= 92 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][92]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][92]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][92]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][92]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][92]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][92]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][92] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_92_contiguous_forward_count = {
    for group_key, group in local.range_92_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 92 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_92_contiguous_base2 = {
    for group_key, group in local.range_92_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 92 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][92]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][92]].to_inclusive - rule.ranges[local.range_keys[group_key][92]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][92]].to_inclusive - rule.ranges[local.range_keys[group_key][92]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][92]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][92]].to_inclusive - rule.ranges[local.range_keys[group_key][92]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_92_squashed = {
    for group_key, group in local.range_92_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 92 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][92] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_93_with_sort_keys = {
    for group_key, group in local.range_92_squashed :
    group_key => length(local.range_keys[group_key]) <= 93 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][93]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][93]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][93]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][93]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][93]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][93]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][93]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][93]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][93]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][93]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_93_sort_keys = {
    for group_key, group in local.range_93_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 93 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_93_sorted = {
    for group_key, group in local.range_93_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 93 ? null : merge(group, {
      rules = [
        for sort_key in local.range_93_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_93_next_contiguous = {
    for group_key, group in local.range_93_sorted :
    group_key => length(local.range_keys[group_key]) <= 93 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][93]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][93]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][93]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][93]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][93]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][93]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][93] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_93_contiguous_forward_count = {
    for group_key, group in local.range_93_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 93 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_93_contiguous_base2 = {
    for group_key, group in local.range_93_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 93 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][93]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][93]].to_inclusive - rule.ranges[local.range_keys[group_key][93]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][93]].to_inclusive - rule.ranges[local.range_keys[group_key][93]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][93]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][93]].to_inclusive - rule.ranges[local.range_keys[group_key][93]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_93_squashed = {
    for group_key, group in local.range_93_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 93 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][93] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_94_with_sort_keys = {
    for group_key, group in local.range_93_squashed :
    group_key => length(local.range_keys[group_key]) <= 94 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][94]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][94]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][94]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][94]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][94]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][94]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][94]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][94]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][94]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][94]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_94_sort_keys = {
    for group_key, group in local.range_94_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 94 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_94_sorted = {
    for group_key, group in local.range_94_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 94 ? null : merge(group, {
      rules = [
        for sort_key in local.range_94_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_94_next_contiguous = {
    for group_key, group in local.range_94_sorted :
    group_key => length(local.range_keys[group_key]) <= 94 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][94]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][94]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][94]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][94]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][94]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][94]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][94] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_94_contiguous_forward_count = {
    for group_key, group in local.range_94_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 94 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_94_contiguous_base2 = {
    for group_key, group in local.range_94_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 94 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][94]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][94]].to_inclusive - rule.ranges[local.range_keys[group_key][94]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][94]].to_inclusive - rule.ranges[local.range_keys[group_key][94]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][94]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][94]].to_inclusive - rule.ranges[local.range_keys[group_key][94]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_94_squashed = {
    for group_key, group in local.range_94_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 94 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][94] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_95_with_sort_keys = {
    for group_key, group in local.range_94_squashed :
    group_key => length(local.range_keys[group_key]) <= 95 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][95]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][95]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][95]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][95]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][95]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][95]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][95]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][95]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][95]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][95]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_95_sort_keys = {
    for group_key, group in local.range_95_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 95 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_95_sorted = {
    for group_key, group in local.range_95_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 95 ? null : merge(group, {
      rules = [
        for sort_key in local.range_95_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_95_next_contiguous = {
    for group_key, group in local.range_95_sorted :
    group_key => length(local.range_keys[group_key]) <= 95 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][95]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][95]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][95]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][95]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][95]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][95]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][95] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_95_contiguous_forward_count = {
    for group_key, group in local.range_95_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 95 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_95_contiguous_base2 = {
    for group_key, group in local.range_95_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 95 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][95]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][95]].to_inclusive - rule.ranges[local.range_keys[group_key][95]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][95]].to_inclusive - rule.ranges[local.range_keys[group_key][95]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][95]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][95]].to_inclusive - rule.ranges[local.range_keys[group_key][95]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_95_squashed = {
    for group_key, group in local.range_95_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 95 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][95] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_96_with_sort_keys = {
    for group_key, group in local.range_95_squashed :
    group_key => length(local.range_keys[group_key]) <= 96 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][96]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][96]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][96]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][96]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][96]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][96]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][96]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][96]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][96]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][96]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_96_sort_keys = {
    for group_key, group in local.range_96_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 96 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_96_sorted = {
    for group_key, group in local.range_96_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 96 ? null : merge(group, {
      rules = [
        for sort_key in local.range_96_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_96_next_contiguous = {
    for group_key, group in local.range_96_sorted :
    group_key => length(local.range_keys[group_key]) <= 96 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][96]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][96]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][96]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][96]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][96]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][96]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][96] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_96_contiguous_forward_count = {
    for group_key, group in local.range_96_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 96 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_96_contiguous_base2 = {
    for group_key, group in local.range_96_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 96 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][96]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][96]].to_inclusive - rule.ranges[local.range_keys[group_key][96]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][96]].to_inclusive - rule.ranges[local.range_keys[group_key][96]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][96]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][96]].to_inclusive - rule.ranges[local.range_keys[group_key][96]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_96_squashed = {
    for group_key, group in local.range_96_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 96 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][96] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_97_with_sort_keys = {
    for group_key, group in local.range_96_squashed :
    group_key => length(local.range_keys[group_key]) <= 97 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][97]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][97]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][97]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][97]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][97]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][97]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][97]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][97]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][97]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][97]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_97_sort_keys = {
    for group_key, group in local.range_97_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 97 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_97_sorted = {
    for group_key, group in local.range_97_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 97 ? null : merge(group, {
      rules = [
        for sort_key in local.range_97_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_97_next_contiguous = {
    for group_key, group in local.range_97_sorted :
    group_key => length(local.range_keys[group_key]) <= 97 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][97]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][97]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][97]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][97]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][97]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][97]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][97] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_97_contiguous_forward_count = {
    for group_key, group in local.range_97_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 97 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_97_contiguous_base2 = {
    for group_key, group in local.range_97_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 97 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][97]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][97]].to_inclusive - rule.ranges[local.range_keys[group_key][97]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][97]].to_inclusive - rule.ranges[local.range_keys[group_key][97]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][97]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][97]].to_inclusive - rule.ranges[local.range_keys[group_key][97]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_97_squashed = {
    for group_key, group in local.range_97_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 97 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][97] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_98_with_sort_keys = {
    for group_key, group in local.range_97_squashed :
    group_key => length(local.range_keys[group_key]) <= 98 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][98]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][98]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][98]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][98]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][98]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][98]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][98]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][98]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][98]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][98]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_98_sort_keys = {
    for group_key, group in local.range_98_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 98 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_98_sorted = {
    for group_key, group in local.range_98_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 98 ? null : merge(group, {
      rules = [
        for sort_key in local.range_98_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_98_next_contiguous = {
    for group_key, group in local.range_98_sorted :
    group_key => length(local.range_keys[group_key]) <= 98 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][98]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][98]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][98]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][98]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][98]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][98]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][98] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_98_contiguous_forward_count = {
    for group_key, group in local.range_98_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 98 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_98_contiguous_base2 = {
    for group_key, group in local.range_98_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 98 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][98]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][98]].to_inclusive - rule.ranges[local.range_keys[group_key][98]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][98]].to_inclusive - rule.ranges[local.range_keys[group_key][98]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][98]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][98]].to_inclusive - rule.ranges[local.range_keys[group_key][98]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_98_squashed = {
    for group_key, group in local.range_98_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 98 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][98] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // Add sort keys to each rule, which we use for sorting.
  range_99_with_sort_keys = {
    for group_key, group in local.range_98_squashed :
    group_key => length(local.range_keys[group_key]) <= 99 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // The sort key uses a complex structure.
          sort_key = contains(keys(rule.ranges), local.range_keys[group_key][99]) ? "${
            // First, we use a JSON encoding of all of the discrete values. This ensures that rules are first
            // sorted by equivalency on all discretes (since they can't be merged if the discretes are different).
            jsonencode(rule.discretes)
          }-${
            // Second, we use a JSON encoding of all ranges except the one we're considering to merge on.
            // This ensures that the rules are sorted by equivalency on all other ranges (since they can't be
            // merged if any of the other ranges are different).
            jsonencode({
              for k, v in rule.ranges:
              k => v
              if k != local.range_keys[group_key][99]
            })
          }-${
            // Third, we use a fixed-length decimal representation of the "from" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "from" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][99]].from_inclusive == null ? "" : rule.ranges[local.range_keys[group_key][99]].from_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][99]].from_inclusive == null ? local.neg_inf : rule.ranges[local.range_keys[group_key][99]].from_inclusive
              )}-${
            // Fourth, we use a fixed-length decimal representation of the "to" value of the range in question.
            // This ensures that when looking forward for possible contiguity, the next rule will always have 
            // a "to" value that is the same or greater.
            format("%s%0${local.digit_count}d",
              rule.ranges[local.range_keys[group_key][99]].to_inclusive == null ? "0" : rule.ranges[local.range_keys[group_key][99]].to_inclusive < 0 ? "" : "0",
              rule.ranges[local.range_keys[group_key][99]].to_inclusive == null ? local.pos_inf : rule.ranges[local.range_keys[group_key][99]].to_inclusive
          )}-${
            // Finally, we add the rule index, so there's always guaranteed to be a unique sort key for each rule,
            // even if somehow they are otherwise identical.
            rule_idx
          }" : (
            // And if the rule we're looking at doesn't have the range key in question, use
            // a sort key that doesn't really matter because this rule will never be merged.
            "no-key-${rule_idx}"
          )
        })
      ]
    })
  }

  // Extract just the sort keys from the rules, and sort them
  range_99_sort_keys = {
    for group_key, group in local.range_99_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 99 ? null : sort([
      for rule in group.rules :
      rule.sort_key
    ])
  }

  // Sort the rules themselves, based on the sort keys
  range_99_sorted = {
    for group_key, group in local.range_99_with_sort_keys :
    group_key => length(local.range_keys[group_key]) <= 99 ? null : merge(group, {
      rules = [
        for sort_key in local.range_99_sort_keys[group_key] :
        [
          for rule in group.rules :
          rule
          if rule.sort_key == sort_key
        ][0]
      ]
    })
  }

  // Determine if a rule is contiguous with the next one
  range_99_next_contiguous = {
    for group_key, group in local.range_99_sorted :
    group_key => length(local.range_keys[group_key]) <= 99 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // It's contiguous with the next rule if:
          // - It's not the last rule
          // - The next rule has a "from" that is overlaping with or adjacent to the "to" value of this rule
          // - For every range other than the one being considered, the next rule's value is exactly equal
          // - For every discrete key, the next rule's value is exactly equal
          contiguous_with_next = (
            // Check if it's the last rule.
            // If this index is equal to the last index value, bail out with "false" because it's
            // the last rule and therefore cannot be contiguous with the next rule.
            rule_idx == length(group.rules) - 1 ? false : (
              // Check if the range we're considering is actually contiguous
              // It's contiguous with the next rule if:
              // - Both rules have the key, AND
              //    - This rule's "to" value is greater than or equal to one less than the next rule's "from" value (forward contiguity)

              // This rule doesn't contain the range key we're checking? That means it can't be contiguous.
              !contains(keys(rule.ranges), local.range_keys[group_key][99]) ? false : (
                // The next rule doesn't contain the range key we're checking? That means it can't be contiguous.
                !contains(keys(group.rules[rule_idx + 1].ranges), local.range_keys[group_key][99]) ? false : (
                  // Check forward contiguity (next rule has higher values)
                  // If this rule's value we're comparing has a null "to", that means we can't compare on the upper (forward) side.
                  // This case should be filtered out in the encapsulation merging.
                  rule.ranges[local.range_keys[group_key][99]].to_inclusive == null ? false : (
                    // If the next rule's value we're comparing has a null "from", that means we can't compare on the upper (forward) side.
                    // This case should be filtered out in the encapsulation merging.
                    group.rules[rule_idx + 1].ranges[local.range_keys[group_key][99]].from_inclusive == null ? false : (
                      // We have two real values to compare, so compare them.
                      // They are forward contiguous if this rule's "to" value is at least adjacent (one less) to the next rule's "from" value
                      rule.ranges[local.range_keys[group_key][99]].to_inclusive < group.rules[rule_idx + 1].ranges[local.range_keys[group_key][99]].from_inclusive - 1 ? false : (
                        // We get here if the first few checks passed (not the last rule, has the key, next rule is forward or reverse contiguous),
                        // so now we ensure no other ranges or discretes are violated.

                        // Check every range other than the one being considered for contiguity
                        // If any are more restrictive, then it is not contiguous
                        0 < length(
                          [
                            for range_key in local.range_keys[group_key] :
                            true
                            if(
                              // Only make this check if it's a range key other than the one we're considering for contiguity
                              range_key != local.range_keys[group_key][99] ? (
                                // This first check ensures that either neither of them have the key, or they both have the key
                                (contains(keys(rule.ranges), range_key) != contains(keys(group.rules[rule_idx + 1].ranges), range_key)) ? true : (
                                  // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                  !contains(keys(rule.ranges), range_key) ? false : (
                                    // This check returns true (is a violation) if both rules have the key but the from value is different
                                    rule.ranges[range_key].from_inclusive != group.rules[rule_idx + 1].ranges[range_key].from_inclusive ? true : (
                                      // This check returns true (is a violation) if both rules have the key but the to value is different
                                      rule.ranges[range_key].to_inclusive != group.rules[rule_idx + 1].ranges[range_key].to_inclusive
                                    )
                                  )
                                )
                              ) : false // false (not a violation) if it's the range key we're considering for contiguity
                            )
                          ],
                        ) ? false :
                        // Check every discrete. If any are more restrictive, then it's not contiguous.
                        0 == length(
                          [
                            for discrete_key in local.discrete_keys[group_key] :
                            true
                            if(
                              // It's a violation if:
                              // - This rule has a key and the next rule doesn't OR
                              // - The next rule has a key and htis rule doesn't
                              // - This rule's value is different than the next rule's value

                              // This first check ensures that either neither of them have the key, or they both have the key
                              (contains(keys(rule.discretes), discrete_key) != contains(keys(group.rules[rule_idx + 1].discretes), discrete_key)) ? true : (
                                // If this rule doesn't have the key, then due to the first check the next rule can't have the key, so this passes (false for violation)
                                !contains(keys(rule.discretes), discrete_key) ? false : (
                                  // This check returns true (is a violation) if both rules have the key but have different values
                                  rule.discretes[discrete_key] != group.rules[rule_idx + 1].discretes[discrete_key]
                                )
                              )
                            )
                          ]
                        )
                      )
                    )
                  )
                )
              )
            )
          )
          }
        )
      ]
    })
  }

  // This step adds a field that counts how many rules, moving forward,
  // this rule is contiguous with.
  range_99_contiguous_forward_count = {
    for group_key, group in local.range_99_next_contiguous :
    group_key => length(local.range_keys[group_key]) <= 99 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        merge(rule, {
          // This works by creating a list of bools of whether a rule is contiguous with the next one,
          // then finding the first false value. This returns the number of contiguous rules without a break.
          // The try is for when they are all contiguous, where index will throw an error when trying to find a false.
          contiguous_forward_count = try(index([
            for compare_rule_idx in range(rule_idx, length(group.rules) - 1) :
            group.rules[compare_rule_idx].contiguous_with_next
          ], false), length(group.rules) - 1 - rule_idx)
        })
      ]
    })
  }

  // This overwrites the contiguous forward count value for base2 range fields (e.g. IPv4 CIDR blocks),
  // where we can't necessarily merge them even if they're contiguous since that might not
  // align with the base2 boundary.
  range_99_contiguous_base2 = {
    for group_key, group in local.range_99_contiguous_forward_count :
    // Don't bother doing anything if we're passed the last range key
    group_key => length(local.range_keys[group_key]) <= 99 ? null : (
      // Don't bother doing anything if this range key isn't marked for base2 alignment
      !contains(group.base2_align_range_keys, local.range_keys[group_key][99]) ? group : merge(group, {
        rules = [
          for rule_idx, rule in group.rules :
          merge(rule, {
            contiguous_forward_count = concat([
              for forward_count in range(rule.contiguous_forward_count, 0, -1) :
              forward_count
              // To see if they can be merged,
              // 1. Check if the combined range has a size that is a power of 2.
              //    We do this by checking if the rounded value is equal to the raw value.
              if floor(log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][99]].to_inclusive - rule.ranges[local.range_keys[group_key][99]].from_inclusive + 1, 2) + 0.5) == log(group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][99]].to_inclusive - rule.ranges[local.range_keys[group_key][99]].from_inclusive + 1, 2) ? (
                // 2. Check if the starting value aligns with that power of 2.
                rule.ranges[local.range_keys[group_key][99]].from_inclusive % (group.rules[rule_idx + forward_count].ranges[local.range_keys[group_key][99]].to_inclusive - rule.ranges[local.range_keys[group_key][99]].from_inclusive + 1) == 0
              ) : false
            ], [0])[0]
          })
        ]
      })
    )
  }

  // Now squash rules that are contiguous.
  range_99_squashed = {
    for group_key, group in local.range_99_contiguous_base2 :
    group_key => length(local.range_keys[group_key]) <= 99 ? null : merge(group, {
      rules = [
        for rule_idx, rule in group.rules :
        {
          discretes = rule.discretes
          ranges = {
            for range_key, range_value in rule.ranges :
            // If it's the range key we're comparing, update it to
            // use the "to" value of the last contiguous rule in this sequence.
            range_key => range_key == local.range_keys[group_key][99] ? merge(range_value, {
              to_inclusive = group.rules[rule_idx + rule.contiguous_forward_count].ranges[range_key].to_inclusive
            }) : range_value
          }
          // Merge the metadata from all of the rules that we just squashed
          metadata = flatten(
            [
              for squashed_idx in range(rule_idx, rule_idx + rule.contiguous_forward_count + 1) :
              group.rules[squashed_idx].metadata
            ]
          )
        }
        // Only include the rule if it's the first rule OR 
        // the previous rule was not contiguous with this one.
        // This removes rules that got squashed into a previous one.
        if rule_idx == 0 ? true : group.rules[rule_idx - 1].contiguous_forward_count == 0
      ]
    })
  }

  // A list of the squashed rules at each level
  squashed_sets = [
    local.range_0_squashed,
    local.range_1_squashed,
    local.range_2_squashed,
    local.range_3_squashed,
    local.range_4_squashed,
    local.range_5_squashed,
    local.range_6_squashed,
    local.range_7_squashed,
    local.range_8_squashed,
    local.range_9_squashed,
    local.range_10_squashed,
    local.range_11_squashed,
    local.range_12_squashed,
    local.range_13_squashed,
    local.range_14_squashed,
    local.range_15_squashed,
    local.range_16_squashed,
    local.range_17_squashed,
    local.range_18_squashed,
    local.range_19_squashed,
    local.range_20_squashed,
    local.range_21_squashed,
    local.range_22_squashed,
    local.range_23_squashed,
    local.range_24_squashed,
    local.range_25_squashed,
    local.range_26_squashed,
    local.range_27_squashed,
    local.range_28_squashed,
    local.range_29_squashed,
    local.range_30_squashed,
    local.range_31_squashed,
    local.range_32_squashed,
    local.range_33_squashed,
    local.range_34_squashed,
    local.range_35_squashed,
    local.range_36_squashed,
    local.range_37_squashed,
    local.range_38_squashed,
    local.range_39_squashed,
    local.range_40_squashed,
    local.range_41_squashed,
    local.range_42_squashed,
    local.range_43_squashed,
    local.range_44_squashed,
    local.range_45_squashed,
    local.range_46_squashed,
    local.range_47_squashed,
    local.range_48_squashed,
    local.range_49_squashed,
    local.range_50_squashed,
    local.range_51_squashed,
    local.range_52_squashed,
    local.range_53_squashed,
    local.range_54_squashed,
    local.range_55_squashed,
    local.range_56_squashed,
    local.range_57_squashed,
    local.range_58_squashed,
    local.range_59_squashed,
    local.range_60_squashed,
    local.range_61_squashed,
    local.range_62_squashed,
    local.range_63_squashed,
    local.range_64_squashed,
    local.range_65_squashed,
    local.range_66_squashed,
    local.range_67_squashed,
    local.range_68_squashed,
    local.range_69_squashed,
    local.range_70_squashed,
    local.range_71_squashed,
    local.range_72_squashed,
    local.range_73_squashed,
    local.range_74_squashed,
    local.range_75_squashed,
    local.range_76_squashed,
    local.range_77_squashed,
    local.range_78_squashed,
    local.range_79_squashed,
    local.range_80_squashed,
    local.range_81_squashed,
    local.range_82_squashed,
    local.range_83_squashed,
    local.range_84_squashed,
    local.range_85_squashed,
    local.range_86_squashed,
    local.range_87_squashed,
    local.range_88_squashed,
    local.range_89_squashed,
    local.range_90_squashed,
    local.range_91_squashed,
    local.range_92_squashed,
    local.range_93_squashed,
    local.range_94_squashed,
    local.range_95_squashed,
    local.range_96_squashed,
    local.range_97_squashed,
    local.range_98_squashed,
    local.range_99_squashed,
  ]

  // The final squashed set of rule sets. For each group, find how many range
  // keys there were, then get the final result from that iteration of squashing.
  // We do it this way so we don't waste memory by holding 100+ iterations of squashing
  // in memory with most of them just being a replicate of the previous level.
  final_contiguous_squashed = {
    for group_key in keys(local.reverse_pass_encapsulate) :
    group_key => local.squashed_sets[length(local.range_keys[group_key]) - 1][group_key]
  }
}
